import os
import asyncio
import sys
from dotenv import load_dotenv
from langchain.memory import ConversationBufferMemory
from langchain_core.prompts import PromptTemplate
from langchain_openai import ChatOpenAI
from asyncio import Event

from app.chatbot.tool_agents.utils.utils import (
    faiss_kiwi,
    classify_legal_query,
)
from app.chatbot.tool_agents.tools import async_ES_search_one

load_dotenv()
OPENAI_API_KEY2 = os.getenv("OPENAI_API_KEY2")


def load_llm():
    return ChatOpenAI(
        model="gpt-3.5-turbo",
        api_key=OPENAI_API_KEY2,
        temperature=0.1,
        max_tokens=1024,
        streaming=False,
    )


class LegalChatbot:
    def __init__(self, faiss_db):
        self.llm = load_llm()
        self.memory = ConversationBufferMemory(
            memory_key="chat_history", return_messages=True
        )
        self.faiss_db = faiss_db
        self.prompt_template = PromptTemplate(
            template="""
        ë‹¹ì‹ ì€ ëŒ€í•œë¯¼êµ­ì˜ ë²•ë¥  ì „ë¬¸ê°€ìž…ë‹ˆë‹¤.  
        í˜„ìž¬ ì‚¬ìš©ìžì˜ ì§ˆë¬¸ì— ëŒ€í•œ **ë²•ë¥ ì  íƒ€ë‹¹ì„±, ì •ë³´ì˜ ëª…í™•ì„±, ìœ ì‚¬ ì‚¬ë¡€ì™€ì˜ ì í•©ì„±**ì„ ê¸°ì¤€ìœ¼ë¡œ  
        'ì‹¤ì‹œê°„ ë³´ê³ ì„œ' í˜•íƒœë¡œ í‰ê°€í•´ ì£¼ì„¸ìš”.
        
            ðŸ“„ ìœ ì‚¬ ìƒë‹´ ê²€ìƒ‰ ê²°ê³¼ (Elasticsearch ê¸°ë°˜/ ):
        {es_context}

        ë‹¤ìŒ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ íŒë‹¨í•˜ì„¸ìš”:

        â“ ì‚¬ìš©ìž ì§ˆë¬¸:
        "{user_query}"


ðŸ“¢ ì§€ì‹œì‚¬í•­:

- ëª¨ë“  íŒë‹¨ì€ **ì‚¬ìš©ìž ì§ˆë¬¸ì˜ í•µì‹¬ í‚¤ì›Œë“œ**ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì‚¼ì•„ì•¼ í•˜ë©°, **Elasticsearch ê²€ìƒ‰ ê²°ê³¼ëŠ” ì°¸ê³ ìš©**ìž…ë‹ˆë‹¤.
- ì§ˆë¬¸ê³¼ ES ê²°ê³¼ì˜ **ì£¼ì œê°€ ëª…ë°±ížˆ ë‹¤ë¥´ë©´ ESëŠ” ë¬´ì‹œ**í•˜ì‹­ì‹œì˜¤.  
  ì˜ˆ: ì§ˆë¬¸ì´ â€˜íŒì‚¬ì˜ ê°ì •ê¸°ë³µâ€™ì¸ë° ESëŠ” â€˜ë³´í–‰ìžâ€™ ê´€ë ¨ì¼ ê²½ìš° â†’ ES ë¬´ì‹œ.

âœ… [íŒë‹¨ ê³µì‹]:

1. ë‹¤ìŒ í•­ëª©ë“¤ì˜ í•©ì‚° ì ìˆ˜ë¥¼ ê³„ì‚°í•˜ì„¸ìš”:
   - ì§ˆë¬¸ ëª…í™•ì„± (0~5)
   - ë²•ë¥  ê´€ë ¨ì„± (0~5)
   - ì •ë³´ ì™„ì „ì„± (0~5)
   - [ë³´ë„ˆìŠ¤] ES ê²€ìƒ‰ íƒ€ì´í‹€ê³¼ ì‚¬ìš©ìž ì§ˆë¬¸ì˜ **ì£¼ì œ ìœ ì‚¬ì„± ì ìˆ˜** (0~5)

2. **ì´ì  14ì  ì´ìƒì¼ ê²½ìš° â†’ `###yes`**  
   **ì´ì  13ì  ì´í•˜ì¼ ê²½ìš° â†’ `###no`**

ðŸ“Œ ì£¼ì˜:
- ESì˜ ì£¼ì œê°€ ê²‰ë³´ê¸°ì—” ë¹„ìŠ·í•´ ë³´ì—¬ë„ **í•µì‹¬ í‚¤ì›Œë“œê°€ ì™„ì „ížˆ ë‹¤ë¥´ë©´ ì ìˆ˜ë¥¼ 0ì ìœ¼ë¡œ ê°„ì£¼**í•˜ì‹­ì‹œì˜¤.
- íŠ¹ížˆ ì§ˆë¬¸ì´ ì§§ë”ë¼ë„ ì‹¤ìž¬ ë²•ë¥  ìš©ì–´ë‚˜ ì£¼ì œê°€ í¬í•¨ëœ ê²½ìš°, ì ê·¹ì ìœ¼ë¡œ ###yes íŒë‹¨ì´ ê°€ëŠ¥í•¨.
- **ë§¤ìš° ë¹„ë²•ë¥ ì ì´ë¼ íŒë‹¨ë˜ëŠ” ìš©ì–´ë“¤ì€ ì§€ì²´ì—†ìœ¼ ###no ë¥¼ ì¶œë ¥í•˜ì„¸ìš”.**

ðŸ§  ìž‘ì„± í˜•ì‹:
- ê° í•­ëª©ì€ **ëª…ì‚¬í˜• í‚¤ì›Œë“œ 5ê°œ**ë¡œ í‘œí˜„
- ë§ˆì§€ë§‰ ì¤„ì— ë°˜ë“œì‹œ `###yes` ë˜ëŠ” `###no`ë¡œ ì¢…ë£Œ



-----------------------------

        ðŸ“Œ [ì‹¤ì‹œê°„ íŒë‹¨ ë³´ê³ ì„œ]

        0. ðŸ”Ž ì‚¬ìš©ìž ì§ˆë¬¸ ìžì²´ì˜ ë²•ë¥ ì„± íŒë‹¨:
        - ì§ˆë¬¸ ìžì²´ê°€ ë²•ì ìœ¼ë¡œ ìœ ì˜ë¯¸í•œê°€? ëª…í™•í•˜ê³  êµ¬ì²´ì ì¸ê°€? 5ë‹¨ì–´ í‘œí˜„

        1. ðŸ“ ì œëª©:
        - ë³¸ ì§ˆë¬¸ì— ì í•©í•œ ìƒë‹´ ì œëª©ì„ 5ë‹¨ì–´ë¡œ í‘œí˜„í•˜ì„¸ìš”.

        2. ðŸ‘¥ ì‚¬ìš©ìž ìƒí™©ê³¼ ìœ ì‚¬í•œê°€?
        - ìœ ì‚¬í•œ ìƒí™©ì´ ì¡´ìž¬í•  ìˆ˜ ìžˆë‹¤ê³  íŒë‹¨ë˜ëŠ”ê±¸ 5ë‹¨ì–´ë¡œ í‘œí˜„í•˜ì„¸ìš”

        3. ðŸ“ í‰ê°€ ì ìˆ˜:
        - ì§ˆë¬¸ ëª…í™•ì„± (0~5):  
        â€» ì§ˆë¬¸ì´ ì§§ë”ë¼ë„ ë²•ë¥  í‚¤ì›Œë“œê°€ ëª…í™•í•˜ë©´ 3ì  ì´ìƒ ë¶€ì—¬  
        - ë²•ë¥  ê´€ë ¨ì„± (0~5):  
        - ì •ë³´ ì™„ì „ì„± (0~5):  
        â€» ì„¸ë¶€ ë‚´ìš©ì´ ë¶€ì¡±í•˜ë”ë¼ë„ ì¼ë°˜ ë²•ë¥  ì˜ì—­ì— ê·€ì† ê°€ëŠ¥í•˜ë©´ 2ì  ì´ìƒ ë¶€ì—¬  
        - ì´ì  (í•©ì‚°):

        4. ðŸ“‹ ì¤‘ê°„ ìš”ì•½:
        - ë²•ë¥ ì ìœ¼ë¡œ ëŒ€ì‘ ê°€ëŠ¥í•œ í•µì‹¬ ë°©í–¥ì„ 5ë‹¨ì–´ë£Œ í‘œí˜„í•˜ì„¸ìš”

        ë§ˆì§€ë§‰ ì¤„ì— íŒë‹¨ ê²°ê³¼ ê¸°ìž…:  
        ###yes ë˜ëŠ” ###no
-----------------------------
        """,
            input_variables=[
                "user_query",
                "es_context",
            ],
        )

    async def build_es_context(self, user_query: str) -> str:
        es_results = await async_ES_search_one([user_query])

        max_score = es_results.get("max_score", 0)
        hits = es_results.get("hits", [])

        if not hits or max_score < 20:
            return "ê´€ë ¨ ìƒë‹´ì‚¬ë¡€ê°€ ì—†ìŠµë‹ˆë‹¤."

        es_context = ""
        for i, item in enumerate(hits[:1], start=1):  # ìƒìœ„ 1ê°œë§Œ ì‚¬ìš©
            es_context += f"\nðŸ“Œ [{i}ë²ˆ ìƒë‹´]\n"
            es_context += f"- ì œëª©(title): {item.get('title', '')}\n"
            es_context += f"- ì§ˆë¬¸(question): {item.get('question', '')}\n"
            es_context += f"- ë‹µë³€(answer): {item.get('answer', '')}\n"

        return es_context.strip()

    async def generate(
        self,
        user_query: str,
        current_yes_count: int = 0,
        stop_event: Event = None,
    ):
        # print("ðŸ” [1] ES ì‚¬ì „ ê²€ìƒ‰(prefetch) ì‹œìž‘")
        es_task = asyncio.create_task(self.build_es_context(user_query))

        # print("ðŸ§  [2] í‚¤ì›Œë“œ ì¶”ì¶œ ë° ì¿¼ë¦¬ ë¶„ì„")
        query_keywords = faiss_kiwi.extract_keywords(user_query, top_k=5)
        faiss_keywords = faiss_kiwi.extract_top_keywords_faiss(
            user_query, self.faiss_db, top_k=5
        )
        legal_score = sum(1 for kw in query_keywords if kw in faiss_keywords) / max(
            len(query_keywords), 1
        )
        query_type = classify_legal_query(user_query, set(faiss_keywords))
        chat_history = self.memory.load_memory_variables({}).get("chat_history", "")

        # print("â³ [3] ES ê²€ìƒ‰ ê²°ê³¼ ëŒ€ê¸°")
        es_context = await es_task
        # print("âœ… [4] ES context í™•ë³´ ì™„ë£Œ")

        # âœ… í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        prompt = self.prompt_template.format(
            chat_history=chat_history,
            user_query=user_query,
            query_keywords=", ".join(query_keywords),
            faiss_keywords=", ".join(faiss_keywords),
            legal_score=f"{legal_score:.2f}",
            query_type=query_type,
            es_context=es_context,
        )

        # print("ðŸ’¬ [5] LLM ì‘ë‹µ ìƒì„± ì‹œìž‘")
        response = await self.llm.ainvoke(prompt)
        full_response = response.content.strip()

        is_no_detected = "###no" in full_response.lower()
        if is_no_detected and stop_event:
            stop_event.set()

        # print("ðŸ’¾ [6] ë©”ëª¨ë¦¬ ì €ìž¥ ë° ê²°ê³¼ ë°˜í™˜")
        self.memory.save_context(
            {"user_query": user_query}, {"response": full_response}
        )

        return {
            "initial_response": full_response,
            "escalate_to_advanced": False,
            "yes_count": current_yes_count,
            "query_type": query_type,
            "is_no": is_no_detected,
        }