import os
import json
from typing import List, Dict
from langchain_openai import ChatOpenAI
from app.chatbot.tool_agents.tools import async_search_consultation
from app.chatbot.tool_agents.utils.utils import validate_model_type
OPENAI_API_KEY = os.environ.get("OPENAI_API_KEY")


def build_relevance_prompt(user_query: str, consultation_results: List[Dict]) -> str:
    formatted = "\n\n".join(
        [
            f"{idx + 1}. ì œëª©: {item['title']}\nì§ˆë¬¸: {item['question']}"
            for idx, item in enumerate(consultation_results)
        ]
    )
    return f"""
ë‹¹ì‹ ì€ ë²•ë¥  ìƒë‹´ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ì‚¬ìš©ìì˜ ì§ˆë¬¸ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:
\"{user_query}\"

ì•„ë˜ëŠ” ì‚¬ìš©ì ì§ˆë¬¸ê³¼ ê´€ë ¨ì´ ìˆì„ ìˆ˜ ìˆëŠ” ê¸°ì¡´ ìƒë‹´ë“¤ì…ë‹ˆë‹¤.

ê° í•­ëª©ì€ 'ì œëª©', 'ì§ˆë¬¸'ìœ¼ë¡œ êµ¬ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤.  
â†’ ë§Œì•½ ì•„ë˜ ìƒë‹´ë“¤ì´ ì‚¬ìš©ì ì§ˆë¬¸ê³¼ **ì£¼ì œì ìœ¼ë¡œ ì™„ì „íˆ ë¬´ê´€**í•˜ë‹¤ë©´, "irrelevant"ë¼ê³ ë§Œ ì‘ë‹µí•˜ì„¸ìš”.  
â†’ ì¼ë¶€ë¼ë„ ê´€ë ¨ì´ ìˆë‹¤ë©´, "relevant"ë¼ê³ ë§Œ ì‘ë‹µí•˜ì„¸ìš”.

===== ìƒë‹´ ëª©ë¡ =====
{formatted}
""".strip()


async def check_relevance_to_consultations(
    user_query: str,
    consultation_results: List[Dict],
    model: str = "gpt-3.5-turbo",
) -> bool:
    validate_model_type(model)
    if not consultation_results:
        return False

    prompt = build_relevance_prompt(user_query, consultation_results)

    llm = ChatOpenAI(
        model=model,
        api_key=OPENAI_API_KEY,
        temperature=0.0,
        streaming=False,
    )

    messages = [
        {
            "role": "system",
            "content": "ë‹¹ì‹ ì€ ë²•ë¥  ìƒë‹´ ì§ˆë¬¸ì˜ ì£¼ì œ ê´€ë ¨ì„±ì„ íŒë³„í•˜ëŠ” AIì…ë‹ˆë‹¤.",
        },
        {"role": "user", "content": prompt},
    ]

    response = await llm.ainvoke(messages)
    result_text = response.content.strip().lower()
    return result_text == "relevant"


def build_choose_one_prompt(user_query: str, consultation_results: List[Dict]) -> str:
    formatted = "\n\n".join(
        [
            f"{idx + 1}. ì œëª©: {item['title']}\nì§ˆë¬¸: {item['question']}\në‹µë³€: {item['answer']}"
            for idx, item in enumerate(consultation_results)
        ]
    )
    return f"""
ë‹¹ì‹ ì€ ë²•ë¥  ìƒë‹´ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ì‚¬ìš©ìì˜ ì§ˆë¬¸ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:
"\{user_query}\"

---

ğŸ“‚ [ì°¸ê³  ìƒë‹´ ì‚¬ë¡€ ëª©ë¡]

ì•„ë˜ëŠ” ì‚¬ìš©ì ì§ˆë¬¸ê³¼ **ë²•ë¥ ì ìœ¼ë¡œ ê´€ë ¨ì´ ìˆì„ ìˆ˜ ìˆëŠ” ìƒë‹´ ë°ì´í„° ëª©ë¡**ì…ë‹ˆë‹¤.  
ê° í•­ëª©ì€ ì œëª©, ì§ˆë¬¸, ë‹µë³€ìœ¼ë¡œ êµ¬ì„±ë˜ì–´ ìˆìœ¼ë©°, ì¼ë¶€ëŠ” í‘œí˜„ì´ ìœ ì‚¬í•´ ë³´ì—¬ë„ **í•µì‹¬ ìŸì ì´ ì™„ì „íˆ ë‹¤ë¥¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.**

ğŸ’¡ ìœ ì˜ì‚¬í•­:
- í•µì‹¬ ë²•ë¥  ìŸì (ì˜ˆ: ê³ ì˜/ê³¼ì‹¤, ëª…ì˜ˆí›¼ì†, ë¶ˆë²•í–‰ìœ„, ì¸ê³¼ê´€ê³„ ë“±)ì´ ë‹¤ë¥´ë©´ **ê´€ë ¨ ì—†ìŒ**ìœ¼ë¡œ ê°„ì£¼í•´ì•¼ í•©ë‹ˆë‹¤.
- ë‹¨ìˆœíˆ ì–´íœ˜ë‚˜ ìƒí™©ì´ ìœ ì‚¬í•´ ë³´ì´ë”ë¼ë„, **ì§ˆë¬¸ì´ ë‹¤ë¥´ë©´ ì„ íƒí•˜ì§€ ë§ˆì„¸ìš”.**
- ë°˜ë“œì‹œ ì§ˆë¬¸ ì¤‘ì‹¬ìœ¼ë¡œ íŒë‹¨í•˜ê³ , **ë‹µë³€ ë‚´ìš©ì— ëŒë ¤ ì„ íƒí•˜ì§€ ì•Šë„ë¡ ì£¼ì˜í•˜ì„¸ìš”.**

---

ğŸ§  [Maieutic Reasoning Instructions]

Step 1: ë¨¼ì € ì‚¬ìš©ì ì§ˆë¬¸ì˜ í•µì‹¬ ë²•ë¥  ìŸì ì„ íŒŒì•…í•˜ì„¸ìš”.  
â†’ Why? ìŸì ì„ ì´í•´í•´ì•¼ ê´€ë ¨ì„±ì´ ìˆëŠ” ìƒë‹´ì„ ê³ ë¥¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

Step 2: ê° ìƒë‹´ í•­ëª©ì´ ì´ ìŸì ê³¼ ì–¼ë§ˆë‚˜ ì¼ì¹˜í•˜ëŠ”ì§€ ë¹„êµí•˜ì„¸ìš”.  
â†’ Why? í‘œí˜„ì´ ìœ ì‚¬í•´ë„, í•µì‹¬ ìŸì ì´ ë‹¤ë¥´ë©´ ê´€ë ¨ì„±ì´ ì—†ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.

Step 3 (ì„ íƒ ë¡œì§ ë‚´ì— ë‚´ì¬ë¨): ìœ ì €ê°€ ì§ˆë¬¸í•œ ë°©ì‹ê³¼ SQL ì§ˆì˜ë¡œ ë°›ì•„ì˜¨ ê° í•­ëª©ì´ **ì–´ë–¤ ë…¼ë¦¬ë¡œ ì—°ê²°ë˜ì—ˆëŠ”ì§€**ë„ ê³ ë ¤í•˜ì„¸ìš”.  
â†’ Why? ê°™ì€ ì¿¼ë¦¬ í‚¤ì›Œë“œë¼ë„ ì˜ë¯¸ê°€ ë‹¤ë¥¼ ìˆ˜ ìˆìœ¼ë©°, ê²€ìƒ‰ì€ ìœ ì‚¬ë„ ê¸°ë°˜ì´ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.

---

âœ… [ìµœì¢… ì„ íƒ ê¸°ì¤€]

- ì˜¤ì§ **ì§ˆë¬¸ì˜ í•µì‹¬ ë²•ë¥  ìŸì ê³¼ ê°€ì¥ ì¼ì¹˜í•˜ëŠ” ìƒë‹´ í•œ ê±´ë§Œ** ì„ íƒ  
- ì„ íƒ ì‚¬ìœ ëŠ” ë‚´ë¶€ì ìœ¼ë¡œ 'ì™œ ì´ í•­ëª©ì´ ë§ëŠ”ì§€'ê¹Œì§€ íŒë‹¨í•´ì•¼ í•˜ë‚˜, ì¶œë ¥ì€ ìˆ«ìë§Œ ì‘ë‹µ  
- ê´€ë ¨ ì—†ëŠ” í•­ëª©ë§Œ ìˆëŠ” ê²½ìš°ëŠ” **ë¹ˆ ë°°ì—´**ë¡œ ì‘ë‹µ

---

â›” ì¶œë ¥ í˜•ì‹ ì•ˆë‚´:

â†’ ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”.  
â†’ í…ìŠ¤íŠ¸, ì‚¬ìœ  ì„¤ëª…, í•­ëª© ë‚´ìš© ìš”ì•½ ëª¨ë‘ ê¸ˆì§€

ì˜ˆì‹œ ì‘ë‹µ:  
[2]

ê´€ë ¨ ìƒë‹´ì´ ì „í˜€ ì—†ì„ ê²½ìš°:  
[]

===== ìƒë‹´ ëª©ë¡ =====
{formatted}
""".strip()


async def choose_best_consultation(
    user_query: str,
    consultation_results: List[Dict],
    model: str = "gpt-3.5-turbo",
) -> Dict:
    if not consultation_results:
        return {"error": "ğŸ” ê´€ë ¨ëœ ìƒë‹´ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.", "status": "no_result"}

    prompt = build_choose_one_prompt(user_query, consultation_results)

    llm = ChatOpenAI(
        model=model,
        api_key=OPENAI_API_KEY,
        temperature=0.1,
        streaming=False,
    )

    messages = [
        {
            "role": "system",
            "content": "ë‹¹ì‹ ì€ ë²•ë¥  ìƒë‹´ ë°ì´í„°ë¥¼ ì •ì œí•˜ëŠ” AI ì „ë¬¸ê°€ì…ë‹ˆë‹¤.",
        },
        {"role": "user", "content": prompt},
    ]

    response = await llm.ainvoke(messages)
    result_text = response.content

    if result_text.strip() in ["[]", "[0]"]:
        return {"error": "ğŸ™ ê´€ë ¨ëœ ìƒë‹´ì´ ì—†ìŠµë‹ˆë‹¤.", "status": "irrelevant"}

    try:
        selected = json.loads(result_text)
        selected_index = int(selected[0]) if isinstance(selected, list) else None

        if selected_index and 0 < selected_index <= len(consultation_results):
            return consultation_results[selected_index - 1]
        else:
            return {
                "error": "â— ì„ íƒëœ ì¸ë±ìŠ¤ê°€ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.",
                "status": "invalid_index",
            }

    except Exception:
        # print("âŒ ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨:", e)
        return {"error": "â— GPT ì‘ë‹µì„ ì´í•´í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", "status": "parse_error"}


# âœ… ì „ì²´ íë¦„# âœ… ì „ì²´ íë¦„ - ìˆ˜ì •ë³¸
async def run_consultation_qualifier(
    user_query: str,
    consultation_results: List[Dict],  # ì™¸ë¶€ì—ì„œ ê²€ìƒ‰ëœ ê²°ê³¼ë¥¼ ë°›ìŒ
    model: str = "gpt-3.5-turbo",
) -> Dict:
    """
    ğŸ“Œ FAISS ê¸°ë°˜ ìœ ì‚¬ ìƒë‹´ ê²€ìƒ‰ â†’ LLM ê¸°ë°˜ ê´€ë ¨ì„± íŒë‹¨ â†’ ìµœì  ìƒë‹´ ì„ íƒ íë¦„
    """

    # âŒ ì¤‘ë³µ ê²€ìƒ‰ ì œê±°
    # consultation_results, _, _ = await async_search_consultation([user_query])

    if not consultation_results:
        return {"error": "ğŸ” ê´€ë ¨ëœ ìƒë‹´ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.", "status": "no_result"}

    is_relevant = await check_relevance_to_consultations(
        user_query, consultation_results, model=model
    )
    if not is_relevant:
        return {
            "error": "ğŸ™ ì‚¬ìš©ì ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ìƒë‹´ì´ ì—†ìŠµë‹ˆë‹¤. ì§ˆë¬¸ì„ ë‹¤ì‹œ ì‘ì„±í•´ë³´ì„¸ìš”.",
            "status": "no_match",
        }

    return await choose_best_consultation(user_query, consultation_results, model=model)

    # fallback ë³´ì™„: title/answer/question í‚¤ê°€ ì—†ìœ¼ë©´ fallback ê°’ í¬í•¨í•˜ì—¬ ë°˜í™˜
    # if not isinstance(result, dict) or not all(
    #     k in result for k in ["title", "question", "answer"]
    # ):
    #     print("âš ï¸ [Qualifier Fallback Triggered] ìœ íš¨í•œ ìƒë‹´ ë°ì´í„°ë¥¼ ì°¾ì§€ ëª»í•¨.")
    #     return {
    #         "title": "ë²•ë¥  ì¼ë°˜",
    #         "question": user_query,
    #         "answer": "í•´ë‹¹ ì§ˆë¬¸ì— ëŒ€í•œ ì •í™•í•œ ìƒë‹´ ë°ì´í„°ë¥¼ ì°¾ì§€ ëª»í–ˆìœ¼ë‚˜, ì¼ë°˜ì ì¸ ë²•ë¥  ì§€ì‹ì— ê¸°ë°˜í•´ ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤.",
    #         "status": "fallback_triggered",
    #     }

    # return result
