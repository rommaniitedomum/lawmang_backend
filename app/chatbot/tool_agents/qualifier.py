import os
import json
from typing import List, Dict
from langchain_openai import ChatOpenAI
from app.chatbot.tool_agents.tools import async_search_consultation
from app.chatbot.tool_agents.utils.utils import validate_model_type
OPENAI_API_KEY = os.environ.get("OPENAI_API_KEY")


def build_relevance_prompt(user_query: str, consultation_results: List[Dict]) -> str:
    formatted = "\n\n".join(
        [
            f"{idx + 1}. ì œëª©: {item['title']}\nì§ˆë¬¸: {item['question']}"
            for idx, item in enumerate(consultation_results)
        ]
    )
    return f"""
ë‹¹ì‹ ì€ ë²•ë¥  ìƒë‹´ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ì‚¬ìš©ìì˜ ì§ˆë¬¸ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:
\"{user_query}\"

ì•„ë˜ëŠ” ì‚¬ìš©ì ì§ˆë¬¸ê³¼ ê´€ë ¨ì´ ìˆì„ ìˆ˜ ìˆëŠ” ê¸°ì¡´ ìƒë‹´ë“¤ì…ë‹ˆë‹¤.

ê° í•­ëª©ì€ 'ì œëª©', 'ì§ˆë¬¸'ìœ¼ë¡œ êµ¬ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤.  
â†’ ë§Œì•½ ì•„ë˜ ìƒë‹´ë“¤ì´ ì‚¬ìš©ì ì§ˆë¬¸ê³¼ **ì£¼ì œì ìœ¼ë¡œ ì™„ì „íˆ ë¬´ê´€**í•˜ë‹¤ë©´, "irrelevant"ë¼ê³ ë§Œ ì‘ë‹µí•˜ì„¸ìš”.  
â†’ ì¼ë¶€ë¼ë„ ê´€ë ¨ì´ ìˆë‹¤ë©´, "relevant"ë¼ê³ ë§Œ ì‘ë‹µí•˜ì„¸ìš”.

===== ìƒë‹´ ëª©ë¡ =====
{formatted}
""".strip()


async def check_relevance_to_consultations(
    user_query: str,
    consultation_results: List[Dict],
    model: str = "gpt-3.5-turbo",
) -> bool:
    validate_model_type(model)
    if not consultation_results:
        return False

    prompt = build_relevance_prompt(user_query, consultation_results)

    llm = ChatOpenAI(
        model=model,
        api_key=OPENAI_API_KEY,
        temperature=0.0,
        streaming=False,
    )

    messages = [
        {
            "role": "system",
            "content": "ë‹¹ì‹ ì€ ë²•ë¥  ìƒë‹´ ì§ˆë¬¸ì˜ ì£¼ì œ ê´€ë ¨ì„±ì„ íŒë³„í•˜ëŠ” AIì…ë‹ˆë‹¤.",
        },
        {"role": "user", "content": prompt},
    ]

    response = await llm.ainvoke(messages)
    result_text = response.content.strip().lower()
    return result_text == "relevant"


def build_choose_one_prompt(user_query: str, consultation_results: List[Dict]) -> str:
    formatted = "\n\n".join(
        [
            f"{idx + 1}. ì œëª©: {item['title']}\nì§ˆë¬¸: {item['question']}\në‹µë³€: {item['answer']}"
            for idx, item in enumerate(consultation_results)
        ]
    )
    return f"""
ë‹¹ì‹ ì€ ë²•ë¥  ìƒë‹´ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ì‚¬ìš©ìì˜ ì§ˆë¬¸ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:
"\{user_query}\"

ì•„ë˜ëŠ” ì‚¬ìš©ì ì§ˆë¬¸ê³¼ **ë²•ë¥ ì ìœ¼ë¡œ ê´€ë ¨ì´ ìˆì„ ìˆ˜ ìˆëŠ” ìƒë‹´ ë°ì´í„° ëª©ë¡**ì…ë‹ˆë‹¤.  
ê° í•­ëª©ì€ ì œëª©, ì§ˆë¬¸, ë‹µë³€ìœ¼ë¡œ êµ¬ì„±ë˜ì–´ ìˆìœ¼ë©°, ì¼ë¶€ëŠ” ìœ ì‚¬í•´ ë³´ì´ì§€ë§Œ ì‹¤ì œ ìŸì ì´ ë‹¤ë¥¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ğŸ’¡ ìœ ì˜ì‚¬í•­:
- ìƒë‹´ ëª©ë¡ì—ëŠ” ì‹¤ì œ ì‚¬ìš©ì ì§ˆë¬¸ê³¼ **ì£¼ì œê°€ ë‹¤ë¥¸ ì‚¬ë¡€**ë„ í¬í•¨ë˜ì–´ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
- íŠ¹íˆ **ë²•ë¥ ì  í•µì‹¬ ìŸì **(ì˜ˆ: ê³ ì˜/ê³¼ì‹¤, ëª…ì˜ˆí›¼ì†, ë¶ˆë²•í–‰ìœ„, ì¸ê³¼ê´€ê³„ ë“±)ì´ **ì¼ì¹˜í•˜ì§€ ì•ŠëŠ” ê²½ìš°**ì—ëŠ” ê´€ë ¨ ì‚¬ë¡€ë¡œ ì„ íƒí•˜ì§€ ë§ˆì„¸ìš”.
- ë‹¨ìˆœíˆ í‘œí˜„ì´ ë¹„ìŠ·í•˜ê±°ë‚˜ ì–¸ëœ» ìœ ì‚¬í•´ ë³´ì—¬ë„, ì§ˆë¬¸ì˜ í•µì‹¬ ìŸì ì´ ë‹¤ë¥´ë©´ ì„ íƒí•˜ë©´ ì•ˆ ë©ë‹ˆë‹¤.

âœ… ë°˜ë“œì‹œ ì‚¬ìš©ì ì§ˆë¬¸ì— **ê°€ì¥ ì •í™•í•˜ê²Œ ëŒ€ì‘í•  ìˆ˜ ìˆëŠ” ìƒë‹´ í•œ ê±´ë§Œ ì„ íƒ**í•˜ì„¸ìš”.  
âœ… ì„ íƒ ê¸°ì¤€ì€ "**ì§ˆë¬¸ì˜ í•µì‹¬ ë²•ë¥  ìŸì ê³¼ ê°€ì¥ ì¼ì¹˜í•˜ëŠ” ìƒë‹´**"ì…ë‹ˆë‹¤.  
â›” íŒë‹¨ ê¸°ì¤€ì€ **ì§ˆë¬¸ ì¤‘ì‹¬**ì…ë‹ˆë‹¤. **ë‹µë³€ë§Œ ë³´ê³  ì„ íƒí•˜ì§€ ë§ˆì„¸ìš”.**

â†’ ì•„ë˜ í˜•ì‹ì˜ **JSON ë°°ì—´ë¡œë§Œ ì‘ë‹µ**í•˜ì„¸ìš”.  
ì„ íƒí•  í•­ëª© ë²ˆí˜¸ë§Œ í¬í•¨í•œ ë¦¬ìŠ¤íŠ¸ë¥¼ ì¶œë ¥í•´ì•¼ í•˜ë©°, í…ìŠ¤íŠ¸ ì„¤ëª…ì€ ê¸ˆì§€ì…ë‹ˆë‹¤.

ì˜ˆì‹œ:  
[2]

â†’ ì‚¬ìš©ì ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ í•­ëª©ì´ **ì „í˜€ ì—†ë‹¤ë©´**, ë¹ˆ ë°°ì—´ì„ ë°˜í™˜í•˜ì„¸ìš”.

ì˜ˆì‹œ:  
[]

===== ìƒë‹´ ëª©ë¡ =====
{formatted}
""".strip()


async def choose_best_consultation(
    user_query: str,
    consultation_results: List[Dict],
    model: str = "gpt-3.5-turbo",
) -> Dict:
    if not consultation_results:
        return {"error": "ğŸ” ê´€ë ¨ëœ ìƒë‹´ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.", "status": "no_result"}

    prompt = build_choose_one_prompt(user_query, consultation_results)

    llm = ChatOpenAI(
        model=model,
        api_key=OPENAI_API_KEY,
        temperature=0.1,
        streaming=False,
    )

    messages = [
        {
            "role": "system",
            "content": "ë‹¹ì‹ ì€ ë²•ë¥  ìƒë‹´ ë°ì´í„°ë¥¼ ì •ì œí•˜ëŠ” AI ì „ë¬¸ê°€ì…ë‹ˆë‹¤.",
        },
        {"role": "user", "content": prompt},
    ]

    response = await llm.ainvoke(messages)
    result_text = response.content

    if result_text.strip() in ["[]", "[0]"]:
        return {"error": "ğŸ™ ê´€ë ¨ëœ ìƒë‹´ì´ ì—†ìŠµë‹ˆë‹¤.", "status": "irrelevant"}

    try:
        selected = json.loads(result_text)
        selected_index = int(selected[0]) if isinstance(selected, list) else None

        if selected_index and 0 < selected_index <= len(consultation_results):
            return consultation_results[selected_index - 1]
        else:
            return {
                "error": "â— ì„ íƒëœ ì¸ë±ìŠ¤ê°€ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.",
                "status": "invalid_index",
            }

    except Exception:
        # print("âŒ ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨:", e)
        return {"error": "â— GPT ì‘ë‹µì„ ì´í•´í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", "status": "parse_error"}


# âœ… ì „ì²´ íë¦„# âœ… ì „ì²´ íë¦„ - ìˆ˜ì •ë³¸
async def run_consultation_qualifier(
    user_query: str,
    consultation_results: List[Dict],  # ì™¸ë¶€ì—ì„œ ê²€ìƒ‰ëœ ê²°ê³¼ë¥¼ ë°›ìŒ
    model: str = "gpt-3.5-turbo",
) -> Dict:
    """
    ğŸ“Œ FAISS ê¸°ë°˜ ìœ ì‚¬ ìƒë‹´ ê²€ìƒ‰ â†’ LLM ê¸°ë°˜ ê´€ë ¨ì„± íŒë‹¨ â†’ ìµœì  ìƒë‹´ ì„ íƒ íë¦„
    """

    # âŒ ì¤‘ë³µ ê²€ìƒ‰ ì œê±°
    # consultation_results, _, _ = await async_search_consultation([user_query])

    if not consultation_results:
        return {"error": "ğŸ” ê´€ë ¨ëœ ìƒë‹´ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.", "status": "no_result"}

    is_relevant = await check_relevance_to_consultations(
        user_query, consultation_results, model=model
    )
    if not is_relevant:
        return {
            "error": "ğŸ™ ì‚¬ìš©ì ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ìƒë‹´ì´ ì—†ìŠµë‹ˆë‹¤. ì§ˆë¬¸ì„ ë‹¤ì‹œ ì‘ì„±í•´ë³´ì„¸ìš”.",
            "status": "no_match",
        }

    return await choose_best_consultation(user_query, consultation_results, model=model)

    # fallback ë³´ì™„: title/answer/question í‚¤ê°€ ì—†ìœ¼ë©´ fallback ê°’ í¬í•¨í•˜ì—¬ ë°˜í™˜
    # if not isinstance(result, dict) or not all(
    #     k in result for k in ["title", "question", "answer"]
    # ):
    #     print("âš ï¸ [Qualifier Fallback Triggered] ìœ íš¨í•œ ìƒë‹´ ë°ì´í„°ë¥¼ ì°¾ì§€ ëª»í•¨.")
    #     return {
    #         "title": "ë²•ë¥  ì¼ë°˜",
    #         "question": user_query,
    #         "answer": "í•´ë‹¹ ì§ˆë¬¸ì— ëŒ€í•œ ì •í™•í•œ ìƒë‹´ ë°ì´í„°ë¥¼ ì°¾ì§€ ëª»í–ˆìœ¼ë‚˜, ì¼ë°˜ì ì¸ ë²•ë¥  ì§€ì‹ì— ê¸°ë°˜í•´ ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤.",
    #         "status": "fallback_triggered",
    #     }

    # return result
