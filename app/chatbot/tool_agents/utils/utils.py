import re
from kiwipiepy import Kiwi
from typing import List, Set, Dict
from collections import Counter
import asyncio
from app.chatbot.memory.global_cache import store_template_in_memory
from app.chatbot.tool_agents.tools import async_ES_search_updater

kiwi = Kiwi()


def insert_hyperlinks_into_text(text: str, hyperlinks: list) -> str:
    if not hyperlinks:
        return text

    for link in hyperlinks:
        label = link.get("label")
        url = link.get("url")
        tooltip = link.get("tooltip", "")

        if not label or not url:
            continue

        # ğŸ” ì •ê·œì‹ìœ¼ë¡œ ë‹¨ì–´ ê²½ê³„ë§Œ ë§¤ì¹­, ì²« ë²ˆì§¸ í•­ëª©ë§Œ êµì²´
        pattern = r"\b" + re.escape(label) + r"\b"
        hyperlink_html = f'<a href="{url}" title="{tooltip}">{label}</a>'
        text = re.sub(pattern, hyperlink_html, text, count=1)

    return text


# --------------------------------------------------------------------------------


def extract_json_from_text(text):
    match = re.search(r"\{[\s\S]*\}", text)
    if match:
        return match.group(0)
    return None


# --------------------------------------------------------------------------------
# ë²•ë¥  ì—¬ë¶€ íŒë‹¨ ê¸°ì¤€: FAISS í‚¤ì›Œë“œ ê¸°ë°˜
def is_legal_query(keywords: List[str], legal_terms: Set[str], threshold=0.3) -> bool:
    legal_count = sum(1 for kw in keywords if kw in legal_terms)
    ratio = legal_count / len(keywords) if keywords else 0
    return ratio >= threshold


def classify_legal_query(user_input: str, legal_terms: Set[str]) -> str:
    tokens = kiwi.tokenize(user_input)
    extracted = [token.form for token in tokens if token.tag in ("NNG", "NNP")]

    if not extracted:
        return "nonlegal"

    legal_count = sum(1 for word in extracted if word in legal_terms)
    ratio = legal_count / len(extracted)

    return "legal" if ratio >= 0.3 else "nonlegal"


# --------------------------------------------------------------------------------
class faiss_kiwi:
    @staticmethod
    def jaccard_similarity(set1, set2):
        """Jaccard ìœ ì‚¬ë„ë¥¼ ì´ìš©í•œ í‚¤ì›Œë“œ ë¹„êµ"""
        intersection = set1.intersection(set2)
        union = set1.union(set2)
        return len(intersection) / len(union) if len(union) > 0 else 0

    @staticmethod
    def extract_top_keywords(es_result, top_k=5):
        if isinstance(es_result, dict) and "hits" in es_result:
            blocks = es_result["hits"]
        elif isinstance(es_result, list):
            blocks = es_result
        else:
            # print("âš ï¸ [extract_top_keywords] ë¹„ì •ìƒì ì¸ es_result:", es_result)
            return []

        return extract_top_keywords(blocks, top_k=top_k)

    @staticmethod
    def filter_keywords_with_jaccard(user_keywords, faiss_keywords, threshold=0.15):
        """ìì¹´ë“œ ìœ ì‚¬ë„ë¥¼ í™œìš©í•˜ì—¬ FAISS í‚¤ì›Œë“œë¥¼ í•„í„°ë§ (ìœ ì € í‚¤ì›Œë“œ ìœ ì§€)"""
        filtered_keywords = set(user_keywords)  # âœ… ìœ ì € ì…ë ¥ í‚¤ì›Œë“œë¥¼ ë¬´ì¡°ê±´ í¬í•¨

        for faiss_word in faiss_keywords:
            max_sim = max(
                faiss_kiwi.jaccard_similarity(set(faiss_word), set(user_word))
                for user_word in user_keywords
            )
            if max_sim >= threshold:
                filtered_keywords.add(faiss_word)

        return list(filtered_keywords)

    @staticmethod
    def extract_keywords(text: str, top_k: int = 5) -> list[str]:
        """
        ì£¼ì–´ì§„ í…ìŠ¤íŠ¸ì—ì„œ ëª…ì‚¬(NNG, NNP) ê¸°ë°˜ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
        """
        tokens = kiwi.tokenize(text)
        nouns = [token.form for token in tokens if token.tag in ("NNG", "NNP")]
        return nouns[:top_k]

    @staticmethod
    def adjust_faiss_keywords(user_input, faiss_keywords):
        """ìœ ì € ì…ë ¥ í‚¤ì›Œë“œì™€ FAISS í‚¤ì›Œë“œë¥¼ ëª¨ë‘ í¬í•¨í•˜ì—¬ ê²€ìƒ‰"""
        user_keywords = faiss_kiwi.extract_keywords(user_input, top_k=5)
        adjusted_keywords = list(set(user_keywords + faiss_keywords))

        # print(f"âœ… [ìµœì¢… ê²€ìƒ‰ í‚¤ì›Œë“œ]: {adjusted_keywords}")
        return adjusted_keywords

    @staticmethod
    def extract_top_keywords_faiss(user_input, faiss_db, top_k=5):
        """FAISS ê²€ìƒ‰ í›„ ìƒìœ„ í‚¤ì›Œë“œ ì¶”ì¶œ (ìœ ì € ì…ë ¥ ë°˜ì˜)"""
        # print(f"ğŸ” [FAISS í‚¤ì›Œë“œ ì¶”ì¶œ] ì…ë ¥: {user_input}")

        search_results = faiss_db.similarity_search(user_input, k=15)
        all_text = " ".join([doc.page_content for doc in search_results])

        faiss_keywords = faiss_kiwi.extract_keywords(all_text, top_k)
        adjusted_keywords = faiss_kiwi.adjust_faiss_keywords(user_input, faiss_keywords)

        # print(f"âœ… [FAISS ìµœì¢… ê²€ìƒ‰ í‚¤ì›Œë“œ] {adjusted_keywords}")
        return adjusted_keywords


def validate_model_type(model):
    if not isinstance(model, str):
        raise TypeError(
            f"âŒ model ì¸ìëŠ” ë¬¸ìì—´(str)ì´ì–´ì•¼ í•©ë‹ˆë‹¤. í˜„ì¬: {type(model)}, ê°’: {model}"
        )


def extract_top_keywords(text_blocks: list[dict], top_k=5) -> list[str]:
    """
    Elasticsearch ê²°ê³¼ ì¤‘ question/answerì—ì„œ ê°€ì¥ ìì£¼ ë“±ì¥í•˜ëŠ” ëª…ì‚¬ ê¸°ë°˜ ìƒìœ„ í‚¤ì›Œë“œ ì¶”ì¶œ
    """
    all_text = " ".join(
        block.get("question", "") + " " + block.get("answer", "")
        for block in text_blocks
    )

    # í•œê¸€/ì˜ë¬¸ ë‹¨ì–´ ì¶”ì¶œ
    tokens = re.findall(r"[ê°€-í£a-zA-Z]{2,}", all_text)

    # ìƒìœ„ ë¹ˆë„ ë‹¨ì–´ ì¶”ì¶œ
    counter = Counter(tokens)
    top_keywords = [word for word, _ in counter.most_common(top_k)]

    return top_keywords


# ------------------------------------------------------------------


# async def update_llm2_template_with_es(template_data: Dict, user_query: str) -> None:
#     template = template_data.get("template", {}) or {}
#     strategy = template_data.get("strategy", {}) or {}
#     precedent = template_data.get("precedent", {}) or {}

#     async def get_keywords_from_texts(texts, top_k=10):
#         es_result = await async_ES_search_one(texts)
#         hits = es_result.get("hits", [])
#         return extract_top_keywords(hits, top_k=top_k) or ["ê¸°ë³¸"]

#     # 1. Summaryìš© í‚¤ì›Œë“œ
#     summary_keywords = await get_keywords_from_texts(
#         [user_query, template.get("summary", "")]
#     )
#     template["summary"] = "updated.summary.from.es: " + ", ".join(summary_keywords)

#     # 2. Explanation
#     explanation_keywords = await get_keywords_from_texts(
#         [template.get("explanation", ""), strategy.get("final_strategy_summary", "")]
#     )
#     template["explanation"] = "updated.explanation.from.es: " + ", ".join(
#         explanation_keywords
#     )

#     # 3. Ref question
#     ref_keywords = await get_keywords_from_texts([template.get("ref_question", "")])
#     template["ref_question"] = "updated.ref_question.from.es: " + ", ".join(
#         ref_keywords
#     )

#     # 4. Strategy summary
#     strat_keywords = await get_keywords_from_texts(
#         [
#             strategy.get("final_strategy_summary", ""),
#             " ".join(strategy.get("decision_tree", [])),
#         ]
#     )
#     strategy["final_strategy_summary"] = "updated.strategy.from.es: " + ", ".join(
#         strat_keywords
#     )
#     strategy["decision_tree"] = [
#         f"ì‚¬ìš©ìê°€ '{kw}' ê´€ë ¨ ì§ˆë¬¸ì„ í•˜ë©´ ë²•ì  ìš”ê±´ì„ ì¤‘ì‹¬ìœ¼ë¡œ íŒë‹¨"
#         for kw in strat_keywords
#     ]

#     # 5. Precedent
#     prec_keywords = await get_keywords_from_texts(
#         [precedent.get("summary", ""), precedent.get("title", "")]
#     )
#     precedent["summary"] = "updated.precedent.from.es: " + ", ".join(prec_keywords)
#     precedent["title"] = f"{prec_keywords[0]} ê´€ë ¨ ì¦ê°• íŒë¡€"

#     store_template_in_memory(
#         {
#             "built": True,
#             "built_by_llm2": True,
#             "updated_by_es": True,
#             "template": template,
#             "strategy": strategy,
#             "precedent": precedent,
#         }
#     )

async def update_llm2_template_with_es(template_data: Dict, user_query: str) -> None:
    template = template_data.get("template", {}) or {}
    strategy = template_data.get("strategy", {}) or {}
    precedent = template_data.get("precedent", {}) or {}

    async def get_snippet(texts, fragment_size=20):
        es_result = await async_ES_search_updater(texts, fragment_size=fragment_size)
        hits = es_result.get("hits", [])
        if hits:
            snippet = hits[0].get("answer_snippet", "") or hits[0].get(
                "question_snippet", ""
            )
            return re.sub(r"</?em>", "", snippet)
        return "ê¸°ë³¸"

    # âœ… Summary
    summary_snippet = await get_snippet([user_query, template.get("summary", "")])
    template["summary"] = f"updated.summary.from.es: {summary_snippet[:50]}"

    # âœ… Explanation
    explanation_snippet = await get_snippet(
        [
            template.get("explanation", ""),
            strategy.get("final_strategy_summary", ""),
        ]
    )
    template["explanation"] = f"updated.explanation.from.es: {explanation_snippet[:50]}"

    # âœ… Ref question
    ref_snippet = await get_snippet([template.get("ref_question", "")])
    template["ref_question"] = f"updated.ref_question.from.es: {ref_snippet[:50]}"

    # âœ… Strategy summary
    strategy_snippet = await get_snippet(
        [
            strategy.get("final_strategy_summary", ""),
            " ".join(strategy.get("decision_tree", [])),
        ]
    )
    strategy["final_strategy_summary"] = (
        f"updated.strategy.from.es: {strategy_snippet[:50]}"
    )
    # strategy["decision_tree"] = [
    #     f"ì‚¬ìš©ìê°€ '{kw}' ê´€ë ¨ ì§ˆë¬¸ì„ í•˜ë©´ ë²•ì  ìš”ê±´ì„ ì¤‘ì‹¬ìœ¼ë¡œ íŒë‹¨"
    #     for kw in faiss_kiwi.extract_keywords(strategy_snippet, top_k=5)
    # ]

    # âœ… Precedent
    precedent_snippet = await get_snippet(
        [precedent.get("summary", ""), precedent.get("title", "")]
    )
    precedent["summary"] = f"updated.precedent.from.es: {precedent_snippet[:50]}"
    prec_keywords = faiss_kiwi.extract_keywords(precedent_snippet, top_k=3)
    precedent["title"] = f"{prec_keywords[0]} ê´€ë ¨ ì¦ê°• íŒë¡€"

    store_template_in_memory(
        {
            "built": True,
            "built_by_llm2": True,
            "updated_by_es": True,
            "template": template,
            "strategy": strategy,
            "precedent": precedent,
        }
    )


async def evalandsave_llm2_template_with_es(
    template_data: Dict, user_query: str
) -> None:
    template = template_data.get("template", {}) or {}
    strategy = template_data.get("strategy", {}) or {}
    precedent = template_data.get("precedent", {}) or {}

    async def get_snippet_and_score(texts, fragment_size=20):
        es_result = await async_ES_search_updater(texts, fragment_size=fragment_size)
        hits = es_result.get("hits", [])
        max_score = es_result.get("max_score", 0)

        if hits:
            snippet = hits[0].get("answer_snippet", "") or hits[0].get(
                "question_snippet", ""
            )
            clean_snippet = re.sub(r"</?em>", "", snippet)
        else:
            clean_snippet = "ê¸°ë³¸"

        return clean_snippet, max_score

    # âœ… ë³‘ë ¬ ì‹¤í–‰
    tasks = await asyncio.gather(
        get_snippet_and_score([user_query, template.get("summary", "")]),
        get_snippet_and_score(
            [
                template.get("explanation", ""),
                strategy.get("final_strategy_summary", ""),
            ]
        ),
        get_snippet_and_score([template.get("ref_question", "")]),
        get_snippet_and_score(
            [
                strategy.get("final_strategy_summary", ""),
                " ".join(strategy.get("decision_tree", [])),
            ]
        ),
        get_snippet_and_score(
            [precedent.get("summary", ""), precedent.get("title", "")]
        ),
    )

    # âœ… ê²°ê³¼ í• ë‹¹
    (summary_snippet, summary_score) = tasks[0]
    (explanation_snippet, explanation_score) = tasks[1]
    (ref_question_snippet, ref_score) = tasks[2]
    (precedent_snippet, _) = tasks[4]

    # âœ… ì—…ë°ì´íŠ¸
    template["summary_raw"] = template.get("summary", "")
    template["summary"] = f"updated.summary.from.es: {summary_snippet[:50]}"
    template["summary_score"] = summary_score

    template["explanation_raw"] = template.get("explanation", "")
    template["explanation"] = f"updated.explanation.from.es: {explanation_snippet[:50]}"
    template["explanation_score"] = explanation_score

    template["ref_question_raw"] = template.get("ref_question", "")
    template["ref_question"] = (
        f"updated.ref_question.from.es: {ref_question_snippet[:50]}"
    )
    template["ref_question_score"] = ref_score

    precedent["summary"] = f"updated.precedent.from.es: {precedent_snippet[:50]}"
    prec_keywords = faiss_kiwi.extract_keywords(precedent_snippet, top_k=3)
    precedent["title"] = f"{prec_keywords[0]} ê´€ë ¨ ì¦ê°• íŒë¡€"

    store_template_in_memory(
        {
            "built": True,
            "built_by_llm2": True,
            "updated_by_es": True,
            "template": template,
            "strategy": strategy,
            "precedent": precedent,
        }
    )


# async def evalandsave_llm2_template_with_es(
#     template_data: Dict, user_query: str
# ) -> None:
#     template = template_data.get("template", {}) or {}
#     strategy = template_data.get("strategy", {}) or {}
#     precedent = template_data.get("precedent", {}) or {}

#     async def get_keywords_and_score(texts, top_k=10):
#         es_result = await async_ES_search_one(texts)
#         hits = es_result.get("hits", [])
#         max_score = es_result.get("max_score", 0)
#         return extract_top_keywords(hits, top_k=top_k) or ["ê¸°ë³¸"], max_score

#     # âœ… ëª¨ë“  ê²€ìƒ‰ í”„ë¦¬íŒ¨ì¹˜ â†’ ë³‘ë ¬ ì‹¤í–‰
#     tasks = await asyncio.gather(
#         get_keywords_and_score([user_query, template.get("summary", "")]),  # 1
#         get_keywords_and_score(
#             [
#                 template.get("explanation", ""),
#                 strategy.get("final_strategy_summary", ""),
#             ]
#         ),  # 2
#         get_keywords_and_score([template.get("ref_question", "")]),  # 3
#         get_keywords_and_score(
#             [
#                 strategy.get("final_strategy_summary", ""),
#                 " ".join(strategy.get("decision_tree", [])),
#             ]
#         ),  # 4
#         get_keywords_and_score(
#             [precedent.get("summary", ""), precedent.get("title", "")]
#         ),  # 5
#     )

#     # âœ… ê²°ê³¼ í• ë‹¹
#     (summary_keywords, summary_score) = tasks[0]
#     (explanation_keywords, explanation_score) = tasks[1]
#     (ref_keywords, ref_score) = tasks[2]
#     (strat_keywords, _) = tasks[3]
#     (prec_keywords, _) = tasks[4]

#     # âœ… Summary
#     template["summary_raw"] = template.get("summary", "")
#     template["summary"] = "updated.summary.from.es: " + ", ".join(summary_keywords)
#     template["summary_score"] = summary_score

#     # âœ… Explanation
#     template["explanation_raw"] = template.get("explanation", "")
#     template["explanation"] = "updated.explanation.from.es: " + ", ".join(
#         explanation_keywords
#     )
#     template["explanation_score"] = explanation_score

#     # âœ… Ref question
#     template["ref_question_raw"] = template.get("ref_question", "")
#     template["ref_question"] = "updated.ref_question.from.es: " + ", ".join(
#         ref_keywords
#     )
#     template["ref_question_score"] = ref_score

#     # âœ… Strategy
#     strategy["final_strategy_summary"] = "updated.strategy.from.es: " + ", ".join(
#         strat_keywords
#     )
#     strategy["decision_tree"] = [
#         f"ì‚¬ìš©ìê°€ '{kw}' ê´€ë ¨ ì§ˆë¬¸ì„ í•˜ë©´ ë²•ì  ìš”ê±´ì„ ì¤‘ì‹¬ìœ¼ë¡œ íŒë‹¨"
#         for kw in strat_keywords
#     ]

#     # âœ… Precedent
#     precedent["summary"] = "updated.precedent.from.es: " + ", ".join(prec_keywords)
#     precedent["title"] = f"{prec_keywords[0]} ê´€ë ¨ ì¦ê°• íŒë¡€"

#     # âœ… ìºì‹œ ì €ì¥
#     store_template_in_memory(
#         {
#             "built": True,
#             "built_by_llm2": True,
#             "updated_by_es": True,
#             "template": template,
#             "strategy": strategy,
#             "precedent": precedent,
#         }
#     )


def calculate_llm2_accuracy_score(template_score: float, user_score: float) -> int:
    """
    ì‚¬ìš©ì ì ìˆ˜(user_score)ëŠ” ë³´ì¡° ì‹ í˜¸ë¡œë§Œ ì‚¬ìš©í•˜ê³ ,
    template_scoreë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ 10~100 ìŠ¤ì¼€ì¼ì˜ ì •í™•ë„ë¥¼ ê³„ì‚°.
    """
    if not template_score or not user_score:
        return 0

    # 1. í…œí”Œë¦¿ ì ìˆ˜ ì •ê·œí™” (10~100 ì‚¬ì´ ê°’ ê¸°ì¤€)
    template_scaled = min(max(template_score, 10), 100)

    # 2. ì‚¬ìš©ì ì ìˆ˜ ê°€ì¤‘ì¹˜ ì ìš© (10~25 ë²”ìœ„ â†’ 0.0 ~ 1.0)
    user_weight = (user_score - 10) / 15  # â†’ 0.0 ~ 1.0

    # 3. ì •í™•ë„ ê³„ì‚° (template ì¤‘ì‹¬, userëŠ” ìµœëŒ€ 10ì  ê°€ì‚°)
    final_score = template_scaled + (10 * user_weight)

    return min(100, int(final_score))
