import os
import sys
import re
import requests
import asyncio
from concurrent.futures import ThreadPoolExecutor
from langchain.tools import Tool
from app.services.consultation import (
    search_consultations,
    search_consultations_by_category,
)
from app.services.consultation_detail_service import get_consultation_detail_by_id
from app.services.precedent_service import (
    search_precedents,
    search_precedents_by_category,
)
# from app.services.mylog_service import get_user_logs, get_user_logs_old
#------------------------------------------------------------API calls
from app.services.precedent_detail_service import fetch_external_precedent_detail
from app.core.database import execute_sql
from langchain_community.tools import TavilySearchResults
from elasticsearch import AsyncElasticsearch
from dotenv import load_dotenv

load_dotenv()

ES_HOST = os.getenv("ES_HOST")
ES_USER = os.getenv("ES_USER")
ES_PASSWORD = os.getenv("ES_PASSWORD")

if not ES_HOST:
    raise ValueError("âŒ ES_HOST í™˜ê²½ë³€ìˆ˜ ëˆ„ë½")
# ---------------------------------------------------------------
executor = ThreadPoolExecutor(max_workers=10)
# âœ… í˜„ì¬ íŒŒì¼ì˜ ìƒìœ„ ê²½ë¡œë¥¼ Python ê²½ë¡œì— ì¶”ê°€

# âœ… 1. ê²€ìƒ‰ ë„êµ¬ ì •ì˜
class llmCOD_tool_sets:
    @staticmethod
    def search_cons():
        """í‚¤ì›Œë“œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë²•ë¥  ìƒë‹´ ì‚¬ë¡€ ê²€ìƒ‰"""
        return Tool(
            name="SearchLegalConsultations",
            func=search_consultations,
            description="ì‚¬ìš©ìê°€ ì…ë ¥í•œ í‚¤ì›Œë“œë¥¼ í¬í•¨í•˜ëŠ” ë²•ë¥  ìƒë‹´ ì‚¬ë¡€ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.",
        )

    # ----------------------------------------------------------------------------------------------

    @staticmethod
    def search_pre():
        """ë²•ë¥  íŒë¡€ ê²€ìƒ‰"""
        return Tool(
            name="SearchLegalPrecedents",
            func=search_precedents,
            description="ì‚¬ìš©ìê°€ ì…ë ¥í•œ í‚¤ì›Œë“œë¥¼ í¬í•¨í•˜ëŠ” ë²•ë¥  íŒë¡€ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.",
        )

    # ----------------------------------------------------------------------------------------------

    # @staticmethod
    # def user_log():
    #     """ì‚¬ìš©ìì˜ ìµœê·¼ ìƒë‹´ ê¸°ë¡ ê²€ìƒ‰"""
    #     return Tool(
    #         name="GetUserLogs",
    #         func=get_user_logs,
    #         description="ì‚¬ìš©ìì˜ ìµœì‹  ìƒë‹´ ê¸°ë¡ì„ ê²€ìƒ‰í•©ë‹ˆë‹¤.",
    #     )

    # @staticmethod
    # def user_log_history():
    #     """ì‚¬ìš©ìì˜ ê³¼ê±° ìƒë‹´ ê¸°ë¡ ê²€ìƒ‰"""
    #     return Tool(
    #         name="GetUserLogsOld",
    #         func=get_user_logs_old,
    #         description="ì‚¬ìš©ìì˜ ê³¼ê±° ìƒë‹´ ê¸°ë¡ì„ ê²€ìƒ‰í•©ë‹ˆë‹¤.",
    #     )

# ---------------------------------------------------------------------------

    # âœ… 4. ëª¨ë“  ë„êµ¬ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜
    @staticmethod
    def get_all_tools():
        """ì •ì˜ëœ ëª¨ë“  ë„êµ¬ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜"""
        return [
            llmCOD_tool_sets.search_pre(),
            llmCOD_tool_sets.search_pre_cat(),
            llmCOD_tool_sets.search_pre_d_id(),
            llmCOD_tool_sets.user_log(),
            llmCOD_tool_sets.user_log_history(),
            llmCOD_tool_sets.search_pre_limited(),  # âœ… ì œí•œ ì ìš©ëœ ê²€ìƒ‰ í•¨ìˆ˜ ì¶”ê°€
            llmCOD_tool_sets.search_cons_limited(),
        ]
        

# ------------------ ì •ë°€ ì„œì¹˜ ìƒë‹´ ì¿¼ë¦¬---------------------------------------------
async def async_search_consultation(keywords):
    """ë¹„ë™ê¸° SQL ìƒë‹´ ê²€ìƒ‰ (ì¹´í…Œê³ ë¦¬ ê¸°ë°˜ í•„í„° ì¶”ê°€)"""
    loop = asyncio.get_running_loop()

    formatted_keywords = ", ".join(f"'{kw}'" for kw in keywords)

    query = f"""
    SET pg_trgm.similarity_threshold = 0.1;

    SELECT 
        id,
        category,
        sub_category,
        title,
        question,
        answer,
        (
            -- title ê°€ì¤‘ì¹˜ (0.45)
            (
                {" + ".join([f"COALESCE(similarity(title, '{kw}'), 0)" for kw in keywords])}
            ) / {len(keywords)} * 0.45
            +
            -- question ê°€ì¤‘ì¹˜ (0.35)
            (
                {" + ".join([f"COALESCE(similarity(question, '{kw}'), 0)" for kw in keywords])}
            ) / {len(keywords)} * 0.35
            +
            -- answer ê°€ì¤‘ì¹˜ (0.15)
            (
                {" + ".join([f"COALESCE(similarity(answer, '{kw}'), 0)" for kw in keywords])}
            ) / {len(keywords)} * 0.15
            +
            -- sub_category ê°€ì¤‘ì¹˜ (0.05)
            (
                {" + ".join([f"COALESCE(similarity(sub_category, '{kw}'), 0)" for kw in keywords])}
            ) / {len(keywords)} * 0.05
            -- categoryëŠ” ê°€ì¤‘ì¹˜ 0ìœ¼ë¡œ ì œì™¸ë¨
        ) AS precise_similarity_score
    FROM legal_consultation
    WHERE 
        title % ANY(ARRAY[{formatted_keywords}])
        OR question % ANY(ARRAY[{formatted_keywords}])
        OR answer % ANY(ARRAY[{formatted_keywords}])
        OR sub_category % ANY(ARRAY[{formatted_keywords}])
    ORDER BY precise_similarity_score DESC
    LIMIT 5;
    """

    # print(f"âœ… [async_search_consultation] ì‹¤í–‰ëœ ì¿¼ë¦¬: \n{query}")  # ğŸ”¥ ì¿¼ë¦¬ ë¡œê·¸ ì¶”ê°€

    # âœ… ìƒë‹´ ë°ì´í„° ê²€ìƒ‰ ì‹¤í–‰
    consultation_results = await loop.run_in_executor(
        executor, execute_sql, query, None, False
    )

    if not consultation_results:
        # print("âŒ [SQL ê²€ìƒ‰ ì‹¤íŒ¨] ìƒë‹´ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return [], [], []  # âœ… ë¹ˆ ë¦¬ìŠ¤íŠ¸ 3ê°œ ë°˜í™˜í•˜ì—¬ ì˜¤ë¥˜ ë°©ì§€!

    # âœ… ê²€ìƒ‰ëœ ìƒë‹´ ë°ì´í„°ì—ì„œ category & title ì¶”ì¶œ
    consultation_categories = list(
        set([row["category"] for row in consultation_results])
    )
    consultation_titles = list(set([row["title"] for row in consultation_results]))

    # print(f"âœ… [ì¶”ì¶œëœ ì¹´í…Œê³ ë¦¬]: {consultation_categories}")
    # print(f"âœ… [ì¶”ì¶œëœ ì œëª©]: {consultation_titles}")

    return (
        consultation_results,
        consultation_categories,
        consultation_titles,
    )  # âœ… ì •ìƒì ì¸ 3ê°œ ë°˜í™˜


# ------------------ ì •ë°€ ì„œì¹˜ íŒë¡€ ì¿¼ë¦¬---------------------------------------------
async def async_search_precedent(categories, titles, user_input_keywords):
    """ë¹„ë™ê¸° SQL íŒë¡€ ê²€ìƒ‰ (ì¹´í…Œê³ ë¦¬ + ì œëª© + ì‚¬ìš©ì ì…ë ¥ í‚¤ì›Œë“œ ê¸°ë°˜, ìµœì‹  10%ë§Œ í•„í„°ë§)"""
    loop = asyncio.get_running_loop()

    def extract_words(text):
        return re.findall(r"\b\w+\b", text)

    title_words = set()
    category_words = set()

    for title in titles:
        title_words.update(extract_words(title))
    for category in categories:
        category_words.update(extract_words(category))

    formatted_categories = ", ".join(f"'{c}'" for c in category_words)
    formatted_titles = ", ".join(f"'{t}'" for t in title_words)
    formatted_user_keywords = ", ".join(f"'{kw}'" for kw in user_input_keywords)

    query = f"""
    SET pg_trgm.similarity_threshold = 0.3;

    WITH top_10_percent AS (
        SELECT *
        FROM precedent
        ORDER BY j_date DESC
    ),

    filtered_precedents AS (
        SELECT id, c_number, c_type, j_date, court, c_name, d_link,
            (
                -- c_name ê°€ì¤‘ì¹˜ (0.7)
                ({" + ".join([f"COALESCE(similarity(c_name, '{kw}'), 0)" for kw in user_input_keywords])}) / {len(user_input_keywords)} * 0.7
                +
                -- c_number ê°€ì¤‘ì¹˜ (0.15)
                ({" + ".join([f"COALESCE(similarity(c_number, '{kw}'), 0)" for kw in user_input_keywords])}) / {len(user_input_keywords)} * 0.15
                +
                -- court ê°€ì¤‘ì¹˜ (0.05)
                ({" + ".join([f"COALESCE(similarity(court, '{kw}'), 0)" for kw in user_input_keywords])}) / {len(user_input_keywords)} * 0.05
                +
                -- c_type ê°€ì¤‘ì¹˜ (0.05)
                ({" + ".join([f"COALESCE(similarity(c_type, '{kw}'), 0)" for kw in user_input_keywords])}) / {len(user_input_keywords)} * 0.05
            ) AS weighted_score
        FROM top_10_percent
        WHERE (
            c_name % ANY(ARRAY[{formatted_user_keywords}])
            OR c_name % ANY(ARRAY[{formatted_titles}])
            OR c_name % ANY(ARRAY[{formatted_categories}])
        )
        ORDER BY weighted_score DESC
        LIMIT 10
    )

    SELECT fp.id, fp.c_number, fp.c_type, fp.j_date, fp.court, fp.c_name, fp.d_link,
        (
            -- c_name ê°€ì¤‘ì¹˜ (0.7)
            ({" + ".join([f"COALESCE(similarity(fp.c_name, '{kw}'), 0)" for kw in user_input_keywords])}) / {len(user_input_keywords)} * 0.7
            +
            -- c_number ê°€ì¤‘ì¹˜ (0.15)
            ({" + ".join([f"COALESCE(similarity(fp.c_number, '{kw}'), 0)" for kw in user_input_keywords])}) / {len(user_input_keywords)} * 0.15
            +
            -- court ê°€ì¤‘ì¹˜ (0.05)
            ({" + ".join([f"COALESCE(similarity(fp.court, '{kw}'), 0)" for kw in user_input_keywords])}) / {len(user_input_keywords)} * 0.05
            +
            -- c_type ê°€ì¤‘ì¹˜ (0.05)
            ({" + ".join([f"COALESCE(similarity(fp.c_type, '{kw}'), 0)" for kw in user_input_keywords])}) / {len(user_input_keywords)} * 0.05
        ) AS final_weighted_score
    FROM filtered_precedents fp
    ORDER BY final_weighted_score DESC
    LIMIT 5;
    """

    precedent_results = await loop.run_in_executor(
        executor, execute_sql, query, None, False
    )

    return precedent_results


# ---------------------------------------------------------------------------------

async def search_tavily_for_precedents(precedent: dict):
    tavily_result = "âŒ Tavily ìš”ì•½ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    casenote_url = ""

    if not precedent:
        return tavily_result, casenote_url

    d_link = precedent.get("d_link", "")
    prec_seq = None

    # ğŸ” precSeq ì¶”ì¶œ ì‹œë„
    if "ID=" in d_link:
        try:
            prec_seq = d_link.split("ID=")[-1].split("&")[0]
            precedent["precSeq"] = prec_seq  # âœ… precSeq ì‚½ì…
        except Exception :
            pass

    if not prec_seq:
        # print("âš ï¸ [Precedent Agent] precSeq ì—†ìŒ")
        return {
            "summary": "âŒ íŒë¡€ precSeqê°€ ì—†ìŠµë‹ˆë‹¤.",
            "casenote_url": "",
            "precedent": precedent,
            "hyperlinks": [],
            "status": "precseq_missing",
        }

    casenote_url = f"https://law.go.kr/LSW/precInfoP.do?precSeq={prec_seq}"

    # ğŸ” Tavily í˜¸ì¶œ
    search_tool = LawGoKRTavilySearch(max_results=5)
    query_path = f"/LSW/precInfoP.do?precSeq={prec_seq}"

    try:
        results = search_tool.run(query_path)

        if isinstance(results, list):
            for result in results:
                url = result.get("url", "")
                content = (
                    result.get("content") or result.get("snippet") or result.get("text")
                )

                if url and f"precSeq={prec_seq}" in url and content:
                    tavily_result = content
                    casenote_url = url
                    break
        elif isinstance(results, str):
            pass  # Tavily ì˜¤ë¥˜ ë©”ì‹œì§€ ë¬´ì‹œ

    except Exception:
        pass  # Tavily ìš”ì²­ ì‹¤íŒ¨ ë¬´ì‹œ

    return tavily_result, casenote_url



# ---------------------------------------------------------------------------------
class LawGoKRTavilySearch:
    """
    Tavilyë¥¼ ì‚¬ìš©í•˜ì—¬ law.go.krì—ì„œë§Œ ê²€ìƒ‰í•˜ë„ë¡ ì œí•œí•˜ëŠ” í´ë˜ìŠ¤
    """

    def __init__(self, max_results=1):  # âœ… ê²€ìƒ‰ ê²°ê³¼ ê°œìˆ˜ ì¡°ì • ê°€ëŠ¥
        self.search_tool = TavilySearchResults(max_results=max_results)

    def run(self, query):
        """
        Tavilyë¥¼ ì‚¬ìš©í•˜ì—¬ íŠ¹ì • URL(law.go.kr)ì—ì„œë§Œ ê²€ìƒ‰ ì‹¤í–‰
        """
        # âœ… íŠ¹ì • ì‚¬ì´íŠ¸(law.go.kr)ì—ì„œë§Œ ê²€ìƒ‰í•˜ë„ë¡ site í•„í„° ì ìš©
        site_restrict_query = f"site:law.go.kr {query}"

        try:
            # âœ… Tavily ê²€ìƒ‰ ì‹¤í–‰
            results = self.search_tool.run(site_restrict_query)

            # âœ… ê²°ê³¼ ì¶œë ¥ (ë””ë²„ê¹…ìš©)
            # print("ğŸ” Tavily ì‘ë‹µ:", results)

            # âœ… ì‘ë‹µì´ ë¦¬ìŠ¤íŠ¸ì¸ì§€ í™•ì¸
            if not isinstance(results, list):
                return (
                    f"âŒ Tavily ê²€ìƒ‰ ì˜¤ë¥˜: ê²°ê³¼ê°€ ë¦¬ìŠ¤íŠ¸ê°€ ì•„ë‹™ë‹ˆë‹¤. ({type(results)})"
                )

            # âœ… `law.go.kr`ì´ í¬í•¨ëœ ê²°ê³¼ë§Œ í•„í„°ë§
            filtered_results = [
                result
                for result in results
                if isinstance(result, dict)
                and "url" in result
                and "law.go.kr" in result["url"]
            ]

            # âœ… ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ì„ ê²½ìš° ì²˜ë¦¬
            if not filtered_results:
                return "âŒ ê´€ë ¨ ë²•ë¥  ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

            return filtered_results
        except Exception as e:
            return f"âŒ Tavily ê²€ìƒ‰ ì˜¤ë¥˜: {str(e)}"


search_tool = LawGoKRTavilySearch(max_results=1)
#---------------------------------------------------------------

# ----------------------------------------------------------------
es: AsyncElasticsearch = None
def inject_es_client(client: AsyncElasticsearch):
    global es
    es = client
# ----------------------------------------------------------------
def init_es_client():
    """ES í´ë¼ì´ì–¸íŠ¸ë¥¼ ë‚´ë¶€ì—ì„œ ì´ˆê¸°í™”í•˜ê³  ì „ì—­ì— ì£¼ì…"""
    global es
    es = AsyncElasticsearch(
        hosts=[ES_HOST],
        basic_auth=(ES_USER, ES_PASSWORD),
        verify_certs=False,
    )
    # print("âœ… ES í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ")

init_es_client()
#----------------------------------------------------------------
async def async_ES_search(keywords):
    """ìµœì í™”ëœ Elasticsearch ê¸°ë°˜ ìƒë‹´ ê²€ìƒ‰ (ë‹¤ì¤‘ í‚¤ì›Œë“œ OR ì¡°ê±´)"""
    index_name = "es_legal_consultation"

    # ğŸ”§ ëª¨ë“  í‚¤ì›Œë“œë¥¼ í•˜ë‚˜ë¡œ ë³‘í•©í•˜ì—¬ íš¨ìœ¨ì ì¸ ë‹¨ì¼ ê²€ìƒ‰
    combined_query = " ".join(keywords)

    query_body = {
        "size": 3,  # ì›í•˜ëŠ” ê²°ê³¼ ìˆ˜
        "query": {
            "multi_match": {
                "query": combined_query,
                "fields": ["title^2", "sub_category^1.5", "question", "answer"],
                "type": "most_fields",
                "operator": "or",
            }
        },
        "_source": ["title", "question", "answer"],  # ğŸ’¡ í•„ìš” í•„ë“œë§Œ ê°€ì ¸ì˜¤ê¸°
    }

    try:
        response = await es.search(index=index_name, body=query_body)
        hits = response["hits"]["hits"]

        if not hits:
            return []

        return [
            {
                "title": hit["_source"].get("title", ""),
                "question": hit["_source"].get("question", ""),
                "answer": hit["_source"].get("answer", ""),
            }
            for hit in hits
            if hit["_source"].get("title")
            and hit["_source"].get("question")
            and hit["_source"].get("answer")
        ]

    except Exception as e:
        return []
# --------------------------------------------------------------------------------

async def async_ES_search_one(keywords):
    """Elasticsearch ê¸°ë°˜ ìƒë‹´ ê²€ìƒ‰ (ìµœì í™” ë²„ì „, OR ì¡°ê±´ ê¸°ë°˜, í•˜ì´ë¼ì´íŠ¸ ì œê±°)"""
    index_name = "es_legal_consultation"

    # ğŸ”§ ëª¨ë“  í‚¤ì›Œë“œë¥¼ í•˜ë‚˜ë¡œ í•©ì³ì„œ ì¿¼ë¦¬ íš¨ìœ¨í™”
    combined_query = " ".join(keywords)

    query_body = {
        "size": 1,
        "query": {
            "multi_match": {
                "query": combined_query,
                "fields": ["title^2", "sub_category^1.5", "question", "answer"],
                "type": "most_fields",
                "operator": "or",
            }
        },
    }

    try:
        response = await es.search(index=index_name, body=query_body)
        hits = response["hits"]["hits"]
        max_score = response["hits"].get("max_score", 0.0)

        if not hits:
            return {"max_score": 0.0, "hits": []}

        hit = hits[0]
        src = hit["_source"]
        return {
            "max_score": max_score,
            "hits": [
                {
                    "title": src.get("title", ""),
                    "question": src.get("question", "")[:50],
                    "answer": src.get("answer", "")[:50],
                }
            ],
        }

    except Exception as e:
        return {"max_score": 0.0, "hits": []}


# ------------------------------------------------------------------------------

async def async_ES_search_updater(keywords, fragment_size=100):
    """Elasticsearch ê¸°ë°˜ ìƒë‹´ ê²€ìƒ‰ (LLM ì…ë ¥ ìµœì í™”: ìµœëŒ€ 100ê¸€ì í•˜ì´ë¼ì´íŠ¸)"""
    index_name = "es_legal_consultation"

    must_clauses = [
        {
            "multi_match": {
                "query": kw,
                "fields": [
                    "title^2",
                    "sub_category^1.5",
                    "question",
                    "answer",
                ],
                "type": "most_fields",
                "operator": "or",
            }
        }
        for kw in keywords
    ]

    query_body = {
        "size": 1,
        "query": {"bool": {"must": must_clauses}},
        "highlight": {
            "fields": {
                "question": {"fragment_size": fragment_size, "number_of_fragments": 1},
                "answer": {"fragment_size": fragment_size, "number_of_fragments": 1},
            }
        },
    }

    try:
        response = await es.search(index=index_name, body=query_body)
        hits = response["hits"]["hits"]
        max_score = response["hits"].get("max_score", 0.0)

        if not hits:
            return {"max_score": 0.0, "hits": []}

        results = []
        for hit in hits:
            src = hit["_source"]
            title = src.get("title", "")
            highlight = hit.get("highlight", {})

            question_highlight = highlight.get(
                "question", [src.get("question", "")[:fragment_size]]
            )[0]
            answer_highlight = highlight.get(
                "answer", [src.get("answer", "")[:fragment_size]]
            )[0]

            if title:
                results.append(
                    {
                        "title": title,
                        "question_snippet": question_highlight,
                        "answer_snippet": answer_highlight,
                    }
                )

        return {"max_score": max_score, "hits": results}

    except Exception as e:
        return {"max_score": 0.0, "hits": []}

