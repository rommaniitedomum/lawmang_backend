import os
import sys
import re
import requests
import asyncio
from concurrent.futures import ThreadPoolExecutor
from langchain.tools import Tool
from app.services.consultation import (
    search_consultations,
    search_consultations_by_category,
)
from app.services.consultation_detail_service import get_consultation_detail_by_id
from app.services.precedent_service import (
    search_precedents,
    search_precedents_by_category,
)
# from app.services.mylog_service import get_user_logs, get_user_logs_old
#------------------------------------------------------------API calls
from app.services.precedent_detail_service import fetch_external_precedent_detail
from app.core.database import execute_sql
from langchain_community.tools import TavilySearchResults
from elasticsearch import AsyncElasticsearch
from dotenv import load_dotenv

load_dotenv()

ES_HOST = os.getenv("ES_HOST")
ES_USER = os.getenv("ES_USER")
ES_PASSWORD = os.getenv("ES_PASSWORD")

if not ES_HOST:
    raise ValueError("‚ùå ES_HOST ÌôòÍ≤ΩÎ≥ÄÏàò ÎàÑÎùΩ")
# ---------------------------------------------------------------
executor = ThreadPoolExecutor(max_workers=10)
# ‚úÖ ÌòÑÏû¨ ÌååÏùºÏùò ÏÉÅÏúÑ Í≤ΩÎ°úÎ•º Python Í≤ΩÎ°úÏóê Ï∂îÍ∞Ä

# ‚úÖ 1. Í≤ÄÏÉâ ÎèÑÍµ¨ Ï†ïÏùò
class llmCOD_tool_sets:
    @staticmethod
    def search_cons():
        """ÌÇ§ÏõåÎìúÎ•º Í∏∞Î∞òÏúºÎ°ú Î≤ïÎ•† ÏÉÅÎã¥ ÏÇ¨Î°Ä Í≤ÄÏÉâ"""
        return Tool(
            name="SearchLegalConsultations",
            func=search_consultations,
            description="ÏÇ¨Ïö©ÏûêÍ∞Ä ÏûÖÎ†•Ìïú ÌÇ§ÏõåÎìúÎ•º Ìè¨Ìï®ÌïòÎäî Î≤ïÎ•† ÏÉÅÎã¥ ÏÇ¨Î°ÄÎ•º Í≤ÄÏÉâÌï©ÎãàÎã§.",
        )

    # ----------------------------------------------------------------------------------------------

    @staticmethod
    def search_pre():
        """Î≤ïÎ•† ÌåêÎ°Ä Í≤ÄÏÉâ"""
        return Tool(
            name="SearchLegalPrecedents",
            func=search_precedents,
            description="ÏÇ¨Ïö©ÏûêÍ∞Ä ÏûÖÎ†•Ìïú ÌÇ§ÏõåÎìúÎ•º Ìè¨Ìï®ÌïòÎäî Î≤ïÎ•† ÌåêÎ°ÄÎ•º Í≤ÄÏÉâÌï©ÎãàÎã§.",
        )

    # ----------------------------------------------------------------------------------------------

    # @staticmethod
    # def user_log():
    #     """ÏÇ¨Ïö©ÏûêÏùò ÏµúÍ∑º ÏÉÅÎã¥ Í∏∞Î°ù Í≤ÄÏÉâ"""
    #     return Tool(
    #         name="GetUserLogs",
    #         func=get_user_logs,
    #         description="ÏÇ¨Ïö©ÏûêÏùò ÏµúÏã† ÏÉÅÎã¥ Í∏∞Î°ùÏùÑ Í≤ÄÏÉâÌï©ÎãàÎã§.",
    #     )

    # @staticmethod
    # def user_log_history():
    #     """ÏÇ¨Ïö©ÏûêÏùò Í≥ºÍ±∞ ÏÉÅÎã¥ Í∏∞Î°ù Í≤ÄÏÉâ"""
    #     return Tool(
    #         name="GetUserLogsOld",
    #         func=get_user_logs_old,
    #         description="ÏÇ¨Ïö©ÏûêÏùò Í≥ºÍ±∞ ÏÉÅÎã¥ Í∏∞Î°ùÏùÑ Í≤ÄÏÉâÌï©ÎãàÎã§.",
    #     )

# ---------------------------------------------------------------------------

    # ‚úÖ 4. Î™®Îì† ÎèÑÍµ¨ Î¶¨Ïä§Ìä∏ Î∞òÌôò
    @staticmethod
    def get_all_tools():
        """Ï†ïÏùòÎêú Î™®Îì† ÎèÑÍµ¨ Î¶¨Ïä§Ìä∏ Î∞òÌôò"""
        return [
            llmCOD_tool_sets.search_pre(),
            llmCOD_tool_sets.search_pre_cat(),
            llmCOD_tool_sets.search_pre_d_id(),
            llmCOD_tool_sets.user_log(),
            llmCOD_tool_sets.user_log_history(),
            llmCOD_tool_sets.search_pre_limited(),  # ‚úÖ Ï†úÌïú Ï†ÅÏö©Îêú Í≤ÄÏÉâ Ìï®Ïàò Ï∂îÍ∞Ä
            llmCOD_tool_sets.search_cons_limited(),
        ]
        

# ------------------ Ï†ïÎ∞Ä ÏÑúÏπò ÏÉÅÎã¥ ÏøºÎ¶¨---------------------------------------------
async def async_search_consultation(keywords):
    """ÎπÑÎèôÍ∏∞ SQL ÏÉÅÎã¥ Í≤ÄÏÉâ (Ïπ¥ÌÖåÍ≥†Î¶¨ Í∏∞Î∞ò ÌïÑÌÑ∞ Ï∂îÍ∞Ä)"""
    loop = asyncio.get_running_loop()

    formatted_keywords = ", ".join(f"'{kw}'" for kw in keywords)

    query = f"""
    SET pg_trgm.similarity_threshold = 0.1;

    SELECT 
        id,
        category,
        sub_category,
        title,
        question,
        answer,
        (
            -- title Í∞ÄÏ§ëÏπò (0.45)
            (
                {" + ".join([f"COALESCE(similarity(title, '{kw}'), 0)" for kw in keywords])}
            ) / {len(keywords)} * 0.45
            +
            -- question Í∞ÄÏ§ëÏπò (0.35)
            (
                {" + ".join([f"COALESCE(similarity(question, '{kw}'), 0)" for kw in keywords])}
            ) / {len(keywords)} * 0.35
            +
            -- answer Í∞ÄÏ§ëÏπò (0.15)
            (
                {" + ".join([f"COALESCE(similarity(answer, '{kw}'), 0)" for kw in keywords])}
            ) / {len(keywords)} * 0.15
            +
            -- sub_category Í∞ÄÏ§ëÏπò (0.05)
            (
                {" + ".join([f"COALESCE(similarity(sub_category, '{kw}'), 0)" for kw in keywords])}
            ) / {len(keywords)} * 0.05
            -- categoryÎäî Í∞ÄÏ§ëÏπò 0ÏúºÎ°ú Ï†úÏô∏Îê®
        ) AS precise_similarity_score
    FROM legal_consultation
    WHERE 
        title % ANY(ARRAY[{formatted_keywords}])
        OR question % ANY(ARRAY[{formatted_keywords}])
        OR answer % ANY(ARRAY[{formatted_keywords}])
        OR sub_category % ANY(ARRAY[{formatted_keywords}])
    ORDER BY precise_similarity_score DESC
    LIMIT 5;
    """

    # print(f"‚úÖ [async_search_consultation] Ïã§ÌñâÎêú ÏøºÎ¶¨: \n{query}")  # üî• ÏøºÎ¶¨ Î°úÍ∑∏ Ï∂îÍ∞Ä

    # ‚úÖ ÏÉÅÎã¥ Îç∞Ïù¥ÌÑ∞ Í≤ÄÏÉâ Ïã§Ìñâ
    consultation_results = await loop.run_in_executor(
        executor, execute_sql, query, None, False
    )

    if not consultation_results:
        # print("‚ùå [SQL Í≤ÄÏÉâ Ïã§Ìå®] ÏÉÅÎã¥ Îç∞Ïù¥ÌÑ∞Î•º Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§.")
        return [], [], []  # ‚úÖ Îπà Î¶¨Ïä§Ìä∏ 3Í∞ú Î∞òÌôòÌïòÏó¨ Ïò§Î•ò Î∞©ÏßÄ!

    # ‚úÖ Í≤ÄÏÉâÎêú ÏÉÅÎã¥ Îç∞Ïù¥ÌÑ∞ÏóêÏÑú category & title Ï∂îÏ∂ú
    consultation_categories = list(
        set([row["category"] for row in consultation_results])
    )
    consultation_titles = list(set([row["title"] for row in consultation_results]))

    # print(f"‚úÖ [Ï∂îÏ∂úÎêú Ïπ¥ÌÖåÍ≥†Î¶¨]: {consultation_categories}")
    # print(f"‚úÖ [Ï∂îÏ∂úÎêú Ï†úÎ™©]: {consultation_titles}")

    return (
        consultation_results,
        consultation_categories,
        consultation_titles,
    )  # ‚úÖ Ï†ïÏÉÅÏ†ÅÏù∏ 3Í∞ú Î∞òÌôò


# ------------------ Ï†ïÎ∞Ä ÏÑúÏπò ÌåêÎ°Ä ÏøºÎ¶¨---------------------------------------------
async def async_search_precedent(categories, titles, user_input_keywords):
    """ÎπÑÎèôÍ∏∞ SQL ÌåêÎ°Ä Í≤ÄÏÉâ (Ïπ¥ÌÖåÍ≥†Î¶¨ + Ï†úÎ™© + ÏÇ¨Ïö©Ïûê ÏûÖÎ†• ÌÇ§ÏõåÎìú Í∏∞Î∞ò, ÏµúÏã† 10%Îßå ÌïÑÌÑ∞ÎßÅ)"""
    loop = asyncio.get_running_loop()

    def extract_words(text):
        return re.findall(r"\b\w+\b", text)

    title_words = set()
    category_words = set()

    for title in titles:
        title_words.update(extract_words(title))
    for category in categories:
        category_words.update(extract_words(category))

    formatted_categories = ", ".join(f"'{c}'" for c in category_words)
    formatted_titles = ", ".join(f"'{t}'" for t in title_words)
    formatted_user_keywords = ", ".join(f"'{kw}'" for kw in user_input_keywords)

    query = f"""
    SET pg_trgm.similarity_threshold = 0.3;

    WITH top_10_percent AS (
        SELECT *
        FROM precedent
        ORDER BY j_date DESC
    ),

    filtered_precedents AS (
        SELECT id, c_number, c_type, j_date, court, c_name, d_link,
            (
                -- c_name Í∞ÄÏ§ëÏπò (0.7)
                ({" + ".join([f"COALESCE(similarity(c_name, '{kw}'), 0)" for kw in user_input_keywords])}) / {len(user_input_keywords)} * 0.7
                +
                -- c_number Í∞ÄÏ§ëÏπò (0.15)
                ({" + ".join([f"COALESCE(similarity(c_number, '{kw}'), 0)" for kw in user_input_keywords])}) / {len(user_input_keywords)} * 0.15
                +
                -- court Í∞ÄÏ§ëÏπò (0.05)
                ({" + ".join([f"COALESCE(similarity(court, '{kw}'), 0)" for kw in user_input_keywords])}) / {len(user_input_keywords)} * 0.05
                +
                -- c_type Í∞ÄÏ§ëÏπò (0.05)
                ({" + ".join([f"COALESCE(similarity(c_type, '{kw}'), 0)" for kw in user_input_keywords])}) / {len(user_input_keywords)} * 0.05
            ) AS weighted_score
        FROM top_10_percent
        WHERE (
            c_name % ANY(ARRAY[{formatted_user_keywords}])
            OR c_name % ANY(ARRAY[{formatted_titles}])
            OR c_name % ANY(ARRAY[{formatted_categories}])
        )
        ORDER BY weighted_score DESC
        LIMIT 10
    )

    SELECT fp.id, fp.c_number, fp.c_type, fp.j_date, fp.court, fp.c_name, fp.d_link,
        (
            -- c_name Í∞ÄÏ§ëÏπò (0.7)
            ({" + ".join([f"COALESCE(similarity(fp.c_name, '{kw}'), 0)" for kw in user_input_keywords])}) / {len(user_input_keywords)} * 0.7
            +
            -- c_number Í∞ÄÏ§ëÏπò (0.15)
            ({" + ".join([f"COALESCE(similarity(fp.c_number, '{kw}'), 0)" for kw in user_input_keywords])}) / {len(user_input_keywords)} * 0.15
            +
            -- court Í∞ÄÏ§ëÏπò (0.05)
            ({" + ".join([f"COALESCE(similarity(fp.court, '{kw}'), 0)" for kw in user_input_keywords])}) / {len(user_input_keywords)} * 0.05
            +
            -- c_type Í∞ÄÏ§ëÏπò (0.05)
            ({" + ".join([f"COALESCE(similarity(fp.c_type, '{kw}'), 0)" for kw in user_input_keywords])}) / {len(user_input_keywords)} * 0.05
        ) AS final_weighted_score
    FROM filtered_precedents fp
    ORDER BY final_weighted_score DESC
    LIMIT 5;
    """

    precedent_results = await loop.run_in_executor(
        executor, execute_sql, query, None, False
    )

    return precedent_results


# ---------------------------------------------------------------------------------

async def search_tavily_for_precedents(precedent: dict):
    tavily_result = "‚ùå Tavily ÏöîÏïΩ Ï†ïÎ≥¥Î•º Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§."
    casenote_url = ""

    if not precedent:
        return tavily_result, casenote_url

    d_link = precedent.get("d_link", "")
    prec_seq = None

    # üîç precSeq Ï∂îÏ∂ú ÏãúÎèÑ
    if "ID=" in d_link:
        try:
            prec_seq = d_link.split("ID=")[-1].split("&")[0]
            precedent["precSeq"] = prec_seq  # ‚úÖ precSeq ÏÇΩÏûÖ
        except Exception :
            pass

    if not prec_seq:
        # print("‚ö†Ô∏è [Precedent Agent] precSeq ÏóÜÏùå")
        return {
            "summary": "‚ùå ÌåêÎ°Ä precSeqÍ∞Ä ÏóÜÏäµÎãàÎã§.",
            "casenote_url": "",
            "precedent": precedent,
            "hyperlinks": [],
            "status": "precseq_missing",
        }

    casenote_url = f"https://law.go.kr/LSW/precInfoP.do?precSeq={prec_seq}"

    # üîç Tavily Ìò∏Ï∂ú
    search_tool = LawGoKRTavilySearch(max_results=5)
    query_path = f"/LSW/precInfoP.do?precSeq={prec_seq}"

    try:
        results = search_tool.run(query_path)

        if isinstance(results, list):
            for result in results:
                url = result.get("url", "")
                content = (
                    result.get("content") or result.get("snippet") or result.get("text")
                )

                if url and f"precSeq={prec_seq}" in url and content:
                    tavily_result = content
                    casenote_url = url
                    break
        elif isinstance(results, str):
            pass  # Tavily Ïò§Î•ò Î©îÏãúÏßÄ Î¨¥Ïãú

    except Exception:
        pass  # Tavily ÏöîÏ≤≠ Ïã§Ìå® Î¨¥Ïãú

    return tavily_result, casenote_url



# ---------------------------------------------------------------------------------
class LawGoKRTavilySearch:
    """
    TavilyÎ•º ÏÇ¨Ïö©ÌïòÏó¨ law.go.krÏóêÏÑúÎßå Í≤ÄÏÉâÌïòÎèÑÎ°ù Ï†úÌïúÌïòÎäî ÌÅ¥ÎûòÏä§
    """

    def __init__(self, max_results=1):  # ‚úÖ Í≤ÄÏÉâ Í≤∞Í≥º Í∞úÏàò Ï°∞Ï†ï Í∞ÄÎä•
        self.search_tool = TavilySearchResults(max_results=max_results)

    def run(self, query):
        """
        TavilyÎ•º ÏÇ¨Ïö©ÌïòÏó¨ ÌäπÏ†ï URL(law.go.kr)ÏóêÏÑúÎßå Í≤ÄÏÉâ Ïã§Ìñâ
        """
        # ‚úÖ ÌäπÏ†ï ÏÇ¨Ïù¥Ìä∏(law.go.kr)ÏóêÏÑúÎßå Í≤ÄÏÉâÌïòÎèÑÎ°ù site ÌïÑÌÑ∞ Ï†ÅÏö©
        site_restrict_query = f"site:law.go.kr {query}"

        try:
            # ‚úÖ Tavily Í≤ÄÏÉâ Ïã§Ìñâ
            results = self.search_tool.run(site_restrict_query)

            # ‚úÖ Í≤∞Í≥º Ï∂úÎ†• (ÎîîÎ≤ÑÍπÖÏö©)
            # print("üîç Tavily ÏùëÎãµ:", results)

            # ‚úÖ ÏùëÎãµÏù¥ Î¶¨Ïä§Ìä∏Ïù∏ÏßÄ ÌôïÏù∏
            if not isinstance(results, list):
                return (
                    f"‚ùå Tavily Í≤ÄÏÉâ Ïò§Î•ò: Í≤∞Í≥ºÍ∞Ä Î¶¨Ïä§Ìä∏Í∞Ä ÏïÑÎãôÎãàÎã§. ({type(results)})"
                )

            # ‚úÖ `law.go.kr`Ïù¥ Ìè¨Ìï®Îêú Í≤∞Í≥ºÎßå ÌïÑÌÑ∞ÎßÅ
            filtered_results = [
                result
                for result in results
                if isinstance(result, dict)
                and "url" in result
                and "law.go.kr" in result["url"]
            ]

            # ‚úÖ Í≤ÄÏÉâ Í≤∞Í≥ºÍ∞Ä ÏóÜÏùÑ Í≤ΩÏö∞ Ï≤òÎ¶¨
            if not filtered_results:
                return "‚ùå Í¥ÄÎ†® Î≤ïÎ•† Ï†ïÎ≥¥Î•º Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§."

            return filtered_results
        except Exception as e:
            return f"‚ùå Tavily Í≤ÄÏÉâ Ïò§Î•ò: {str(e)}"


search_tool = LawGoKRTavilySearch(max_results=1)
#---------------------------------------------------------------

# ----------------------------------------------------------------
es: AsyncElasticsearch = None
def inject_es_client(client: AsyncElasticsearch):
    global es
    es = client
# ----------------------------------------------------------------
def init_es_client():
    """ES ÌÅ¥ÎùºÏù¥Ïñ∏Ìä∏Î•º ÎÇ¥Î∂ÄÏóêÏÑú Ï¥àÍ∏∞ÌôîÌïòÍ≥† Ï†ÑÏó≠Ïóê Ï£ºÏûÖ"""
    global es
    es = AsyncElasticsearch(
        hosts=[ES_HOST],
        basic_auth=(ES_USER, ES_PASSWORD),
        verify_certs=False,
    )
    # print("‚úÖ ES ÌÅ¥ÎùºÏù¥Ïñ∏Ìä∏ Ï¥àÍ∏∞Ìôî ÏôÑÎ£å")

init_es_client()
#----------------------------------------------------------------
async def async_ES_search(keywords):
    """ÏµúÏ†ÅÌôîÎêú Elasticsearch Í∏∞Î∞ò ÏÉÅÎã¥ Í≤ÄÏÉâ (Îã§Ï§ë ÌÇ§ÏõåÎìú OR Ï°∞Í±¥)"""
    index_name = "es_legal_consultation"

    # üîß Î™®Îì† ÌÇ§ÏõåÎìúÎ•º ÌïòÎÇòÎ°ú Î≥ëÌï©ÌïòÏó¨ Ìö®Ïú®Ï†ÅÏù∏ Îã®Ïùº Í≤ÄÏÉâ
    combined_query = " ".join(keywords)

    query_body = {
        "size": 3,  # ÏõêÌïòÎäî Í≤∞Í≥º Ïàò
        "query": {
            "multi_match": {
                "query": combined_query,
                "fields": ["title^2", "sub_category^1.5", "question", "answer"],
                "type": "most_fields",
                "operator": "or",
            }
        },
        "_source": ["title", "question", "answer"],  # üí° ÌïÑÏöî ÌïÑÎìúÎßå Í∞ÄÏ†∏Ïò§Í∏∞
    }

    try:
        response = await es.search(index=index_name, body=query_body)
        hits = response["hits"]["hits"]

        if not hits:
            return []

        return [
            {
                "title": hit["_source"].get("title", ""),
                "question": hit["_source"].get("question", ""),
                "answer": hit["_source"].get("answer", ""),
            }
            for hit in hits
            if hit["_source"].get("title")
            and hit["_source"].get("question")
            and hit["_source"].get("answer")
        ]

    except Exception as e:
        return []
# --------------------------------------------------------------------------------

async def async_ES_search_one(keywords):
    """Elasticsearch Í∏∞Î∞ò ÏÉÅÎã¥ Í≤ÄÏÉâ (ÏµúÏ†ÅÌôî Î≤ÑÏ†Ñ, OR Ï°∞Í±¥ Í∏∞Î∞ò, ÌïòÏù¥ÎùºÏù¥Ìä∏ Ï†úÍ±∞)"""
    index_name = "es_legal_consultation"

    # üîß Î™®Îì† ÌÇ§ÏõåÎìúÎ•º ÌïòÎÇòÎ°ú Ìï©Ï≥êÏÑú ÏøºÎ¶¨ Ìö®Ïú®Ìôî
    combined_query = " ".join(keywords)

    query_body = {
        "size": 1,
        "query": {
            "multi_match": {
                "query": combined_query,
                "fields": ["title^2", "sub_category^1.5", "question", "answer"],
                "type": "most_fields",
                "operator": "or",
            }
        },
    }

    try:
        response = await es.search(index=index_name, body=query_body)
        hits = response["hits"]["hits"]
        max_score = response["hits"].get("max_score", 0.0)

        if not hits:
            return {"max_score": 0.0, "hits": []}

        hit = hits[0]
        src = hit["_source"]
        return {
            "max_score": max_score,
            "hits": [
                {
                    "title": src.get("title", ""),
                    "question": src.get("question", "")[:50],
                    "answer": src.get("answer", "")[:50],
                }
            ],
        }

    except Exception as e:
        return {"max_score": 0.0, "hits": []}


# ------------------------------------------------------------------------------

# async def async_ES_search_updater(keywords, fragment_size=100):
#     """Elasticsearch Í∏∞Î∞ò ÏÉÅÎã¥ Í≤ÄÏÉâ (LLM ÏûÖÎ†• ÏµúÏ†ÅÌôî: ÏµúÎåÄ 100Í∏ÄÏûê ÌïòÏù¥ÎùºÏù¥Ìä∏)"""
#     index_name = "es_legal_consultation"

#     must_clauses = [
#         {
#             "multi_match": {
#                 "query": kw,
#                 "fields": [
#                     "title^2",
#                     "sub_category^1.5",
#                     "question",
#                     "answer",
#                 ],
#                 "type": "most_fields",
#                 "operator": "or",
#             }
#         }
#         for kw in keywords
#     ]

#     query_body = {
#         "size": 1,
#         "query": {"bool": {"must": must_clauses}},
#         "highlight": {
#             "fields": {
#                 "question": {"fragment_size": fragment_size, "number_of_fragments": 1},
#                 "answer": {"fragment_size": fragment_size, "number_of_fragments": 1},
#             }
#         },
#     }

#     try:
#         response = await es.search(index=index_name, body=query_body)
#         hits = response["hits"]["hits"]
#         max_score = response["hits"].get("max_score", 0.0)

#         if not hits:
#             return {"max_score": 0.0, "hits": []}

#         results = []
#         for hit in hits:
#             src = hit["_source"]
#             title = src.get("title", "")
#             highlight = hit.get("highlight", {})

#             question_highlight = highlight.get(
#                 "question", [src.get("question", "")[:fragment_size]]
#             )[0]
#             answer_highlight = highlight.get(
#                 "answer", [src.get("answer", "")[:fragment_size]]
#             )[0]

#             if title:
#                 results.append(
#                     {
#                         "title": title,
#                         "question_snippet": question_highlight,
#                         "answer_snippet": answer_highlight,
#                     }
#                 )

#         return {"max_score": max_score, "hits": results}

#     except Exception as e:
#         return {"max_score": 0.0, "hits": []}

async def async_ES_search_updater(keywords, fragment_size=100):
    es = AsyncElasticsearch()

    # ‚úÖ body = [{header}, {body}, {header}, {body}, ...]
    msearch_body = []
    for kw in keywords:
        msearch_body.append({"index": "es_legal_consultation"})
        msearch_body.append(
            {
                "size": 1,
                "query": {
                    "multi_match": {
                        "query": kw,
                        "fields": ["title^2", "sub_category^1.5", "question", "answer"],
                        "type": "most_fields",
                        "operator": "or",
                    }
                },
                "highlight": {
                    "fields": {
                        "question": {
                            "fragment_size": fragment_size,
                            "number_of_fragments": 1,
                        },
                        "answer": {
                            "fragment_size": fragment_size,
                            "number_of_fragments": 1,
                        },
                    }
                },
            }
        )

    # ‚úÖ msearch Ïã§Ìñâ
    try:
        res = await es.msearch(body=msearch_body)

        best_hit = {"max_score": 0.0, "hits": []}

        for r in res["responses"]:
            hits = r.get("hits", {}).get("hits", [])
            if not hits:
                continue
            hit = hits[0]
            score = hit.get("_score", 0.0)
            if score > best_hit["max_score"]:
                src = hit["_source"]
                hl = hit.get("highlight", {})
                best_hit = {
                    "max_score": score,
                    "hits": [
                        {
                            "title": src.get("title", ""),
                            "question_snippet": hl.get(
                                "question", [src.get("question", "")[:fragment_size]]
                            )[0],
                            "answer_snippet": hl.get(
                                "answer", [src.get("answer", "")[:fragment_size]]
                            )[0],
                        }
                    ],
                }

        return best_hit

    except Exception as e:
        print(f"‚ùå MSEARCH Error: {e}")
        return {"max_score": 0.0, "hits": []}