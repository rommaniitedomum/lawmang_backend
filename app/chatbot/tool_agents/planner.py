import os
import json
import difflib
from app.chatbot.tool_agents.tools import async_ES_search
from langchain_openai import ChatOpenAI
from typing import List, Dict
from app.chatbot.tool_agents.tools import LawGoKRTavilySearch
from app.chatbot.memory.templates import get_default_strategy_template
from app.chatbot.tool_agents.utils.utils import validate_model_type

OPENAI_API_KEY = os.environ.get("OPENAI_API_KEY")


def get_llm(model: str, temperature: float = 0.3) -> ChatOpenAI:
    validate_model_type(model)  # âœ… íƒ€ì… ì²´í¬

    return ChatOpenAI(
        model=model,
        api_key=OPENAI_API_KEY,
        temperature=temperature,
        streaming=False,
    )


# âœ… ì‘ë‹µ í…œí”Œë¦¿ ìƒì„±
async def generate_response_template(
    title: str,
    question: str,
    answer: str,
    user_query: str,
    es_results: list[dict] = None,
    model: str = "gpt-3.5-turbo",
) -> dict:
    # âœ… es_resultsê°€ ì—†ìœ¼ë©´ ì§ì ‘ í˜¸ì¶œ
    if es_results is None:
        es_results = await async_ES_search([user_query])

    # ğŸ”¹ ES ìƒë‹´ ë‚´ìš© ì¶”ê°€ êµ¬ì„±
    es_context = ""
    if es_results:
        es_context += "ESì—ì„œ ê²€ìƒ‰í•œ ìœ ì‚¬ ìƒë‹´ 3ê±´:\n"
        for i, item in enumerate(es_results, start=1):
            es_context += f"\nğŸ“Œ [{i}ë²ˆ ìƒë‹´]\n"
            es_context += f"- ì œëª©(title): {item.get('title', '')}\n"
            es_context += f"- ì§ˆë¬¸(question): {item.get('question', '')}\n"
            es_context += f"- ë‹µë³€(answer): {item.get('answer', '')}\n"
    prompt = f"""
ë‹¹ì‹ ì€ ë²•ë¥  ìƒë‹´ ì‘ë‹µ í…œí”Œë¦¿ì„ êµ¬ì„±í•˜ëŠ” AIì…ë‹ˆë‹¤.

Let's think step by step and explain why each part is valid.

---

ğŸ“Œ ì‚¬ìš©ì ì§ˆë¬¸:
"{user_query}"

ğŸ“ ì°¸ê³ ìë£Œ (ES ê²€ìƒ‰ ê¸°ë°˜ ìƒë‹´):
{es_context}

ğŸ“ SQL ê¸°ë°˜ ìœ ì‚¬ ìƒë‹´:
- ì œëª©(title): "{title}"
- ì§ˆë¬¸(question): "{question}"
- ë‹µë³€(answer): "{answer}"

---

ğŸ›  ì‘ì—… ì§€ì‹œ:

ğŸ’¡ ì•„ë˜ ìƒë‹´ ì˜ˆì‹œì—ëŠ” ì˜¤ë‹µì´ ì„ì—¬ ìˆì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì£¼ì˜ ê¹Šê²Œ ê²€í† í•˜ì„¸ìš”.  
ğŸ’¡ ìƒë‹´ ì˜ˆì‹œëŠ” ì°¸ê³ ìš©ì¼ ë¿ì´ë©°, ë°˜ë“œì‹œ **ì‚¬ìš©ì ì§ˆë¬¸ì„ ì¤‘ì‹¬ìœ¼ë¡œ íŒë‹¨**í•˜ê³  ì‘ë‹µ ì „ëµì„ êµ¬ì„±í•´ì•¼ í•©ë‹ˆë‹¤.  
ğŸ’¡ ì‚¬ìš©ì ì§ˆë¬¸ì€ **ìµœì†Œí•œì˜ ìš”êµ¬ì‚¬í•­ì´ì ì‘ë‹µì˜ ì¤‘ì‹¬**ì…ë‹ˆë‹¤.  
    - ì§ˆë¬¸ì— í¬í•¨ëœ **ì‚¬ì‹¤ê´€ê³„, í‘œí˜„, ì •í™©**ì„ ë¹ ì§ì—†ì´ ë°˜ì˜í•˜ì„¸ìš”.  
    - ê·¸ ìœ„ì— ë²•ë¥ ì  í•´ì„ì„ ë§ë¶™ì—¬ **ì „ëµì ìœ¼ë¡œ êµ¬ì„±**í•´ì•¼ í•©ë‹ˆë‹¤.  
    â†’ Why? ì§ˆë¬¸ìì˜ ê²½í—˜ê³¼ ì„œìˆ ì€ ì‘ë‹µì—ì„œ ë°˜ë“œì‹œ ì¡´ì¤‘ë°›ì•„ì•¼ í•˜ë©°, ë²•ì  ì¡°ì–¸ì€ í˜„ì‹¤ê³¼ ë§ë‹¿ì•„ì•¼ í•˜ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.

âœ… ì°¸ê³  ìƒë‹´ ì¤‘ ì‚¬ìš©ì ì§ˆë¬¸ê³¼ **ë²•ë¥ ì ìœ¼ë¡œ ê´€ë ¨ ìˆëŠ” ëª¨ë“  ë ˆí¼ëŸ°ìŠ¤(ë¬¸ì¥, ê°œë…, ì¡°í•­ ë“±)**ëŠ” ì „ëµ êµ¬ì„±ì— ë°˜ë“œì‹œ ë°˜ì˜í•˜ì„¸ìš”.  
â›” ë‹¨, ì‚¬ìš©ì ì§ˆë¬¸ì˜ í•µì‹¬ ìŸì ê³¼ ì–´ê¸‹ë‚˜ëŠ” ë‚´ìš©ì€ ì¸ìš©í•˜ê±°ë‚˜ ì°¸ê³ í•˜ì§€ ë§ˆì„¸ìš”.  
â†’ Why? í•µì‹¬ ìŸì ê³¼ ë¬´ê´€í•œ ì •ë³´ëŠ” ì˜¤íˆë ¤ ì˜ëª»ëœ ë°©í–¥ìœ¼ë¡œ ì•ˆë‚´í•  ìˆ˜ ìˆê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.

---

ë‹¤ìŒ ë„¤ ê°€ì§€ í•­ëª©ì„ ìˆœì„œì— ë§ì¶° ì‘ì„±í•˜ì„¸ìš”:  
ê° í•­ëª©ì€ ë‹¨ìˆœ ìƒì„±ì´ ì•„ë‹ˆë¼, ê·¸ **ì„ íƒê³¼ ì „ê°œê°€ í•©ë¦¬ì ì¸ ê·¼ê±°ì— ê¸°ë°˜**í•˜ë„ë¡ ì„¤ê³„ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.  
ê° ë¬¸ë‹¨ ë‚´ë¶€ì—ì„œëŠ” â€œì™œ ì´ë ‡ê²Œ íŒë‹¨í–ˆëŠ”ê°€â€ë¥¼ LLMì´ ìŠ¤ìŠ¤ë¡œ ë‚©ë“í•˜ë©° ì‘ì„±í•˜ì„¸ìš”.

---

1. **summary**  
- ì‚¬ìš©ì ì§ˆë¬¸ì—ì„œ ë“œëŸ¬ë‚œ í•µì‹¬ ë²•ë¥  ìŸì ê³¼ ì†í•´ ë˜ëŠ” ê°ˆë“±ì˜ ì›ì¸ì„ í•œ ë¬¸ë‹¨ìœ¼ë¡œ ìš”ì•½í•©ë‹ˆë‹¤.  
- ì§ˆë¬¸ì— í¬í•¨ëœ í‘œí˜„ê³¼ ì •í™©ì„ ëª…ì‹œì ìœ¼ë¡œ í¬í•¨í•˜ë©°, ë‹¨ìˆœíˆ â€˜ê°€ëŠ¥/ë¶ˆê°€ëŠ¥â€™ìœ¼ë¡œ ê²°ë¡  ì§“ì§€ ë§ˆì„¸ìš”.  
â†’ Why? ì§ˆë¬¸ìëŠ” ê²°ë¡ ë³´ë‹¤ **ìƒí™©ì„ ëª…í™•íˆ í•´ì„ë°›ê³  ì‹¶ì–´ í•˜ë©°**, ì •í™© ì¤‘ì‹¬ì˜ ìš”ì•½ì´ ì‹ ë¢°ë¥¼ í˜•ì„±í•©ë‹ˆë‹¤.

2. **explanation**  
- ì‚¬ìš©ìì˜ ìƒí™©ê³¼ ê°ì •ì„ ë¨¼ì € ì–¸ê¸‰í•˜ë©° ê³µê°ì„ í‘œí˜„í•˜ì„¸ìš” (ì˜ˆ: ì–µìš¸í•¨, ë‹¹í™©ìŠ¤ëŸ¬ì›€ ë“±).  
- ì´ì–´ì„œ ë²•ë¥ ì ìœ¼ë¡œ ì¤‘ìš”í•œ ìŸì ì„ ì§šê³ , ì‹¤ë¬´ìƒ í˜„ì‹¤ì ì¸ í•´ì„ê³¼ ì „ëµì  ì„ íƒì§€ë¥¼ ì„¤ëª…í•˜ì„¸ìš”.  
- "ì‹¤ì œ ë²•ì›ì—ì„œëŠ”", "í˜„ì‹¤ì ìœ¼ë¡œëŠ”", "ì‹¤ë¬´ìƒìœ¼ë¡œëŠ”" ë“±ì˜ í‘œí˜„ì„ í™œìš©í•´ ì‹¤ì§ˆì  ì¡°ì–¸ì„ ì œê³µí•˜ì„¸ìš”.  
- ìœ ì‚¬ ìƒë‹´ ë‚´ìš©ì´ ë„ì›€ì´ ë˜ëŠ” ê²½ìš°, í•´ë‹¹ ë‚´ìš©ì€ ì „ëµì ìœ¼ë¡œ ìš”ì•½í•˜ì—¬ ì¸ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  
â†’ Why? ì‚¬ìš©ìëŠ” ë²•ë¦¬ í•´ì„ë³´ë‹¤ **ì‹¤ì œ ë„ì›€ì´ ë˜ëŠ” ë§**ì„ ì›í•˜ë©°, ê°ì •ì  ì—°ê²°ì´ ì„¤ë“ì˜ ê¸°ë°˜ì´ ë©ë‹ˆë‹¤.

3. **hyperlinks**  
- ì„¤ëª…ì—ì„œ ì–¸ê¸‰í•œ ë²•ë ¹, íŒë¡€ ë“±ì„ ì‹¤ì œ ì¶œì²˜ì™€ í•¨ê»˜ label + URL í˜•ì‹ìœ¼ë¡œ ì •ë¦¬í•˜ì„¸ìš”.  
- law.go.kr ê³µì‹ ì‚¬ì´íŠ¸ ë§í¬ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.  
â†’ Why? ì œì‹œëœ ì •ë³´ì˜ ì‹ ë¢°ì„±ì„ ë†’ì´ê³ , ì‚¬ìš©ìê°€ ì§ì ‘ ê²€í† í•  ìˆ˜ ìˆë„ë¡ í•˜ë ¤ëŠ” ëª©ì ì…ë‹ˆë‹¤.

4. **ref_question**  
- ë°˜ë“œì‹œ ì‚¬ìš©ì ì§ˆë¬¸(user_query)ì„ **ê·¸ëŒ€ë¡œ** ë°˜í™˜í•˜ì„¸ìš”.  
- SQL ìƒë‹´ ì§ˆë¬¸ì´ ì•„ë‹Œ **ì‚¬ìš©ì ì§ˆë¬¸ì´ ê¸°ì¤€**ì…ë‹ˆë‹¤.  
â†’ Why? ìƒì„± ì‘ë‹µì€ í•­ìƒ ì› ì§ˆë¬¸ ê¸°ì¤€ìœ¼ë¡œ ì†Œê¸‰ ê°€ëŠ¥í•´ì•¼ í•˜ë©°, íšŒê³ ì  ê²€í† ì˜ ê¸°ì¤€ì ì´ ë˜ì–´ì•¼ í•˜ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.

---

ğŸ§¾ ì‘ë‹µ í˜•ì‹ ì˜ˆì‹œ:

{{
  "summary": "...",
  "explanation": "...",
  "hyperlinks": [{{"label": "...", "url": "..."}}],
  "ref_question": "..."
}}
"""

    llm = get_llm(model, temperature=0.3)

    messages = [
        {
            "role": "system",
            "content": "ë‹¹ì‹ ì€ ë²•ë¥  ì‘ë‹µ í…œí”Œë¦¿ì„ ìƒì„±í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.",
        },
        {"role": "user", "content": prompt},
    ]

    try:
        response = llm.invoke(messages)
        return json.loads(response.content)
    except Exception:
        return {"error": "GPT ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨"}


# âœ… ì „ëµ ìƒì„±
async def generate_response_strategy(
    explanation: str,
    user_query: str,
    hyperlinks: list = None,
    previous_strategy: dict = None,
    model: str = "gpt-3.5-turbo",
) -> dict:
    hyperlinks = hyperlinks or []

    hyperlink_text = (
        "\n".join([f"- {item['label']}: {item['url']}" for item in hyperlinks])
        if hyperlinks
        else "ì—†ìŒ"
    )

    previous_strategy_text = (
        json.dumps(previous_strategy, ensure_ascii=False, indent=2)
        if previous_strategy
        else "ì—†ìŒ"
    )

    prompt = f"""
ë‹¹ì‹ ì€ ë²•ë¥  ì‘ë‹µ ì „ëµì„ ì„¤ê³„í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
Let's think step by step and explain why each part is valid.

[ì‚¬ìš©ì ì§ˆë¬¸]
"{user_query}"

[ì„¤ëª… ì´ˆì•ˆ]
"{explanation}"

[ê´€ë ¨ ë²•ë¥  ë§í¬]
{hyperlink_text}

[ì´ì „ ì „ëµì´ ìˆëŠ” ê²½ìš° ì°¸ê³ ìš©]
{previous_strategy_text}

--- ì‘ì—… ì§€ì‹œ ---

ğŸ’¡ ì•„ë˜ ì‘ë‹µ ë‚´ìš© ì¤‘ ì¼ë¶€ëŠ” ì˜¤ë‹µì´ í¬í•¨ë˜ì–´ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.  
â†’ Why? ìƒì„±í˜• AIì˜ ì‘ë‹µì€ ì¢…ì¢… ì •í™•ë„ë‚˜ ë¬¸ë§¥ìƒ ì˜¤ë¥˜ê°€ ì¡´ì¬í•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ, ë°˜ë“œì‹œ ì‚¬ìš©ì ì…ì¥ì—ì„œ í™•ì¸í•˜ê³  íŒë‹¨í•´ì•¼ í•©ë‹ˆë‹¤.

ğŸ’¡ ì œê³µëœ ì„¤ëª…ì´ ì‚¬ìš©ì ì§ˆë¬¸ê³¼ ì£¼ì œê°€ ëª…ë°±íˆ ë‹¤ë¥¸ ê²½ìš°, í•´ë‹¹ ë¬¸ì¥ì€ ë°˜ë“œì‹œ ì‚­ì œí•´ì•¼ í•©ë‹ˆë‹¤.  
â†’ Why? í•µì‹¬ ìŸì ê³¼ ë¬´ê´€í•œ ì •ë³´ëŠ” ì˜ëª»ëœ ì „ëµì„ ìœ ë„í•˜ê±°ë‚˜ ì‹ ë¢°ë„ë¥¼ ë–¨ì–´ëœ¨ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.  

ì˜ˆ: ê°€ì¡±ì´ ìƒí•´ë¥¼ ë‹¹í–ˆìŠµë‹ˆë‹¤ â†’ ì´í˜¼ ê´€ë ¨ íŒë¡€ëŠ” ì œì™¸  

ë‹¤ìŒ í•­ëª©ë“¤ì„ ìˆœì„œì— ë§ì¶° ì‘ì„±í•˜ì„¸ìš”.  
ê° í•­ëª©ì€ ë‹¨ìˆœ ìš”ì•½ì´ ì•„ë‹ˆë¼, "ì™œ ì´ë ‡ê²Œ íŒë‹¨í–ˆëŠ”ê°€?"ì— ëŒ€í•´ LLMì´ ë‚´ë¶€ì ìœ¼ë¡œ ì„¤ëª… ê°€ëŠ¥í•´ì•¼ í•©ë‹ˆë‹¤.

1. **tone**  
- ì‚¬ìš©ìì˜ ê°ì •, ìƒí™©, ì§ˆë¬¸ ë§¥ë½ì„ ê³ ë ¤í•´ ì‘ë‹µì˜ ë§íˆ¬ë¥¼ ì„¤ê³„í•˜ì„¸ìš”.  
â†’ Why? ë§íˆ¬ëŠ” ë‹¨ìˆœ í‘œí˜„ì„ ë„˜ì–´, ì‚¬ìš©ìì˜ ìˆ˜ìš©ì„±ê³¼ ì‹ ë¢°ë„ì— ì§ì ‘ì ì¸ ì˜í–¥ì„ ì¤ë‹ˆë‹¤.

2. **structure**  
- ì‘ë‹µì„ ì–´ë–¤ íë¦„ìœ¼ë¡œ êµ¬ì„±í• ì§€ ë‹¨ê³„ë³„ë¡œ ì„¤ëª…í•˜ì„¸ìš”. (ì˜ˆ: ê³µê° â†’ ìŸì  ìš”ì•½ â†’ ì¡°ì–¸ â†’ ë²•ë ¹ ìš”ì•½ ë“±)  
â†’ Why? ì¼ê´€ëœ íë¦„ì€ ì‚¬ìš©ì ì´í•´ë¥¼ ë•ê³ , ê³¼ë„í•œ ì •ë³´ í˜¼ë€ì„ ë°©ì§€í•©ë‹ˆë‹¤.

3. **decision_tree**  
- ë²•ë¥  íŒë‹¨ì— í•„ìš”í•œ ì¡°ê±´/ì˜ˆì™¸ ë¶„ê¸°ë¥¼ **Tree-of-Thought** í˜•ì‹ìœ¼ë¡œ êµ¬ì„±í•˜ì„¸ìš”.  
â†’ Why? í›„ì† LLMì´ ì´ êµ¬ì¡°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë…¼ë¦¬ì ìœ¼ë¡œ íŒë‹¨í•˜ê±°ë‚˜ ìš”ì•½í•  ìˆ˜ ìˆë„ë¡ í•´ì•¼ í•©ë‹ˆë‹¤.  

4. **final_strategy_summary**  
- ì „ì²´ ì „ëµì„ í•œ ë¬¸ë‹¨ìœ¼ë¡œ ìš”ì•½í•˜ì„¸ìš”.  
â†’ Why? ìš”ì•½ì€ ì‚¬ìš©ìë¿ ì•„ë‹ˆë¼, ì‹œìŠ¤í…œ ê°„ ê³µìœ ì—ë„ ìœ ë¦¬í•œ ì •ë³´ ì¶•ì•½ ì§€ì ì…ë‹ˆë‹¤.

5. **recommended_links**  
- ì„¤ëª…ì—ì„œ ì–¸ê¸‰í•œ ë²•ë ¹ì´ë‚˜ íŒë¡€ ë§í¬ë¥¼ `label + URL (law.go.kr)` í˜•ì‹ìœ¼ë¡œ ì •ë¦¬í•˜ì„¸ìš”.  
â†’ Why? ì‚¬ìš©ìì—ê²Œ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì¶œì²˜ë¥¼ ì œê³µí•¨ìœ¼ë¡œì¨ ì •ë³´ì˜ ê³µì‹ì„±ì„ í™•ë³´í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.


--- ğŸ§  ê²°ì • íŠ¸ë¦¬ ì˜ˆì‹œ (Few-shot / Tree-of-Thought êµ¬ì¡°) ---

ì˜ˆ:  
"ì‚¬ìš©ìê°€ ì‘ì—… ì¤‘ ê³ ì†Œë¥¼ ë‹¹í•´ ì¼ì„ ë†“ì³¤ë‹¤ê³  ì§ˆë¬¸í•œ ê²½ìš°"

decision_tree: [
  "1. ê³ ì†Œê°€ ì‚¬ì‹¤ì— ê·¼ê±°í•œ ì •ë‹¹í•œ ê³ ì†Œì¸ê°€?",
  "   â”œâ”€ ì˜ˆ: ì†í•´ë°°ìƒ ì²­êµ¬ ì–´ë ¤ì›€ â†’ ê³ ì†ŒëŠ” ì •ë‹¹í•œ ê¶Œë¦¬ í–‰ì‚¬ì´ë¯€ë¡œ ë¶ˆë²•í–‰ìœ„ ì„±ë¦½ ì•ˆ ë¨",
  "   â””â”€ ì•„ë‹ˆì˜¤: í—ˆìœ„ ë˜ëŠ” ì•…ì˜ì  ê³ ì†Œ â†’ ë¶ˆë²•í–‰ìœ„ ì„±ë¦½ ê°€ëŠ¥ì„± â†’ ì†í•´ë°°ìƒ ì²­êµ¬ ê°€ëŠ¥",
  "2. ê³ ì†Œì™€ ì†í•´ ì‚¬ì´ ì¸ê³¼ê´€ê³„ê°€ ëª…í™•í•œê°€?",
  "   â”œâ”€ ì˜ˆ: ì‹¤ì œ ì†í•´(ì¼ì‹¤ìˆ˜ìµ ë“±)ë¥¼ ì…ì¦í•  ìˆ˜ ìˆë‹¤ë©´ ë°°ìƒ ì¸ì • ê°€ëŠ¥",
  "   â””â”€ ì•„ë‹ˆì˜¤: ê³ ì†Œì™€ ì†í•´ê°€ ë¬´ê´€í•˜ê±°ë‚˜ ì¶”ì • ìˆ˜ì¤€ â†’ ì†í•´ë°°ìƒ ì¸ì • ì–´ë ¤ì›€"
]

--- end ---

ì‘ë‹µ í˜•ì‹ (JSON):
{{
  "tone": "...",
  "structure": "...",
  "decision_tree": ["..."],
  "final_strategy_summary": "...",
  "recommended_links": [{{"label": "...", "url": "..."}}]
}}
"""

    llm = get_llm(model, temperature=0.3)

    messages = [
        {"role": "system", "content": "ë‹¹ì‹ ì€ ë²•ë¥  ìƒë‹´ ì „ëµì„ ì„¤ê³„í•˜ëŠ” AIì…ë‹ˆë‹¤."},
        {"role": "user", "content": prompt},
    ]

    try:
        response = llm.invoke(messages)
        strategy_raw = response.content
        strategy = json.loads(strategy_raw)
    except Exception as e:
        default_strategy = get_default_strategy_template()
        default_strategy["error"] = "GPT ì „ëµ íŒŒì‹± ì‹¤íŒ¨"
        return default_strategy

    search_tool = LawGoKRTavilySearch(max_results=3)
    tavily_results = search_tool.run(user_query)

    evaluation = await evaluate_strategy_with_tavily(strategy, tavily_results)
    strategy["evaluation"] = evaluation

    return strategy


# âœ… ì „ëµ í‰ê°€
async def evaluate_strategy_with_tavily(
    strategy: dict,
    tavily_results: list,
    model: str = "gpt-3.5-turbo",
) -> dict:
    if not tavily_results or not isinstance(tavily_results, list):
        return {
            "needs_revision": False,
            "reason": "Tavily ê²°ê³¼ê°€ ì—†ê±°ë‚˜ ìœ íš¨í•˜ì§€ ì•ŠìŒ",
            "tavily_snippets": [],
        }

    tavily_snippets = [
        (result.get("content") or result.get("snippet") or result.get("text")).strip()
        for result in tavily_results[:3]
        if result.get("content") or result.get("snippet") or result.get("text")
    ]

    if not tavily_snippets:
        return {
            "needs_revision": False,
            "reason": "Tavily ìš”ì•½ ì¶”ì¶œ ì‹¤íŒ¨",
            "tavily_snippets": [],
        }

    combined = "\n\n".join(
        [f"[ìš”ì•½ {i + 1}]\n{text}" for i, text in enumerate(tavily_snippets)]
    )

    prompt = f"""
ë‹¹ì‹ ì€ ë²•ë¥  ìƒë‹´ ì „ëµì„ í‰ê°€í•˜ëŠ” AIì…ë‹ˆë‹¤.

[GPT ì „ëµ ìš”ì•½]
{strategy.get("final_strategy_summary", "")}

[Tavily ìš”ì•½ ê²°ê³¼ë“¤]
{combined}

--- ì‘ì—… ì§€ì‹œ ---
1. GPT ì „ëµì´ Tavily ìš”ì•½ ê²°ê³¼ì˜ **í•µì‹¬ ìŸì  ë° ë²•ë¥  ë…¼ë¦¬ë¥¼ ì¶©ì‹¤íˆ ë°˜ì˜**í•˜ê³  ìˆëŠ”ì§€ í‰ê°€í•˜ì„¸ìš”.  
â†’ Why? í•µì‹¬ ìš”ì†Œê°€ ëˆ„ë½ë˜ì—ˆê±°ë‚˜ ë²•ë¦¬ì™€ ë‹¤ë¥´ë©´ ì‚¬ìš©ìì—ê²Œ ì˜ëª»ëœ ì•ˆë‚´ê°€ ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

2. í‘œí˜„ ë°©ì‹ì´ë‚˜ ë¬¸ì¥ ìˆœì„œê°€ ë‹¬ë¼ë„, **í•µì‹¬ ë‚´ìš©ì´ ì¼ì¹˜í•œë‹¤ë©´** ê¸ì • í‰ê°€í•˜ì„¸ìš”.  
â†’ Why? ë™ì¼í•œ ì˜ë¯¸ë¥¼ ë‹´ê³  ìˆë‹¤ë©´ í‘œí˜„ì˜ ì°¨ì´ëŠ” ë¬¸ì œê°€ ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.

3. ì „ëµì´ ì˜¤í•´ë¥¼ ìœ ë°œí•˜ê±°ë‚˜, ì‚¬ì‹¤ê´€ê³„/ì±…ì„ê´€ê³„ì˜ íë¦„ì— **ëª…ë°±í•œ ì˜¤ë¥˜**ê°€ ìˆë‹¤ë©´ ë¶€ì • í‰ê°€í•˜ì„¸ìš”.

---

ğŸ§ª ìµœì¢… íŒë‹¨:

- ì „ëµì´ **ì¶©ë¶„íˆ ìœ íš¨í•˜ê³ , ì‹¤ë¬´ì ìœ¼ë¡œë„ ë¬¸ì œì—†ë‹¤ë©´**: `true`
- ì „ëµì´ **ì¤‘ëŒ€í•œ ëˆ„ë½, ì˜¤ë¥˜, ë¹„í˜„ì‹¤ì  ì¡°ì–¸**ì„ í¬í•¨í•œë‹¤ë©´: `false`

{{
  "needs_revision": true or false,
  "reason": "...",
  "tavily_snippets": [...]
}}
"""

    llm = get_llm(model, temperature=0.2)
    messages = [
        {"role": "system", "content": "ë²•ë¥  ë¶„ì„ê°€ AIì…ë‹ˆë‹¤."},
        {"role": "user", "content": prompt},
    ]

    try:
        response = llm.invoke(messages)
        return json.loads(response.content)
    except Exception as e:
        return {
            "needs_revision": False,
            "reason": "GPT ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨",
            "tavily_snippets": tavily_snippets,
        }


# âœ… ì „ëµ ë³´ì™„
async def revise_strategy_with_feedback(
    original_strategy: dict,
    tavily_snippets: list,
    model: str = "gpt-3.5-turbo",
) -> dict:
    combined_snippets = "\n\n".join(
        [
            f"[Tavily ìš”ì•½ {i + 1}]\n{snippet}"
            for i, snippet in enumerate(tavily_snippets)
        ]
    )

    prompt = f"""
Let's think step by step and explain why each part is valid.

ë‹¹ì‹ ì€ ë‹¤ë¥¸ LLMì´ ì°¸ì¡°í•  ìˆ˜ ìˆëŠ” **ì™„ì„±ëœ ë²•ë¥  ì „ëµ í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±í•˜ëŠ” ìƒì„±í˜• ì—ì´ì „íŠ¸**ì…ë‹ˆë‹¤.  
ì…ë ¥ìœ¼ë¡œ ì£¼ì–´ì§„ ì „ëµì€ ì¼ë¶€ ë¶ˆì™„ì „í•˜ê±°ë‚˜ ëª¨í˜¸í•  ìˆ˜ ìˆìœ¼ë©°, ì´ë¥¼ ëª…í™•í•˜ê²Œ ë³´ê°•í•´ì•¼ í•©ë‹ˆë‹¤.

ì•„ë˜ Tavily ìš”ì•½ì„ ì°¸ê³ í•˜ì—¬ ì „ëµì„ ë³´ì™„í•˜ì„¸ìš”.
[Tavily ìš”ì•½ë“¤]
{combined_snippets}

[ê¸°ì¡´ ì „ëµ ìš”ì•½]
{original_strategy.get("final_strategy_summary", "")}

--- ì‘ì—… ì§€ì‹œ ---
1. ê¸°ì¡´ ì „ëµ ë‚´ìš©ì„ ê°€ëŠ¥í•œ í•œ í™œìš©í•˜ë˜, **Tavily ìš”ì•½ì˜ í•µì‹¬ ë²•ë¦¬/ë…¼ì  ì •ë³´ë¥¼ ë°˜ë“œì‹œ ë°˜ì˜**í•˜ì„¸ìš”.  
â†’ Why? ê¸°ì¡´ ì „ëµì˜ ë¬¸ì²´ì™€ íë¦„ì„ ì‚´ë¦¬ë˜, ë¶€ì¡±í•œ ì •ë³´ë¥¼ ë³´ì™„í•˜ì—¬ ì‹ ë¢°ë„ë¥¼ ë†’ì´ê¸° ìœ„í•¨ì…ë‹ˆë‹¤.

2. **Tavily**ë¼ëŠ” ë‹¨ì–´ëŠ” ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”.  
â›” â€œTavilyì— ë”°ë¥´ë©´â€, â€œì¶œì²˜: Tavilyâ€, â€œTavily ìš”ì•½â€ ë“± **ëª¨ë“  í˜•íƒœì˜ ì§ì ‘ ì¸ìš©ì€ ê¸ˆì§€**  
â†’ Why? ì‚¬ìš©ìì—ê²Œ ì™¸ë¶€ ì¶œì²˜ê°€ ë…¸ì¶œë˜ë©´ í˜¼ë€ì´ë‚˜ ì‹ ë¢° ì €í•˜ê°€ ë°œìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

3. **ì‘ë‹µ êµ¬ì¡°(JSON í•„ë“œ)ëŠ” ê·¸ëŒ€ë¡œ ìœ ì§€**í•´ì•¼ í•˜ë©°,  
   `tone`, `structure`, `decision_tree`, `final_strategy_summary`, `recommended_links` ìˆœì„œë¡œ ì‘ì„±í•˜ì„¸ìš”.


--- ê²°ì • íŠ¸ë¦¬ ì˜ˆì‹œ (Few-shot) ---

ì˜ˆ:  
"ì‚¬ìš©ìê°€ ì‘ì—… ì¤‘ ê³ ì†Œë¥¼ ë‹¹í•´ ì¼ì„ ë†“ì³¤ë‹¤ê³  ì§ˆë¬¸í•œ ê²½ìš°"

decision_tree: [
  "1. ê³ ì†Œê°€ ì‚¬ì‹¤ì— ê·¼ê±°í•œ ì •ë‹¹í•œ ê³ ì†Œì¸ê°€?",
  "   â”œâ”€ ì˜ˆ: ì†í•´ë°°ìƒ ì²­êµ¬ ì–´ë ¤ì›€ â†’ ê³ ì†ŒëŠ” ì •ë‹¹í•œ ê¶Œë¦¬ í–‰ì‚¬ì´ë¯€ë¡œ ë¶ˆë²•í–‰ìœ„ ì„±ë¦½ ì•ˆ ë¨",
  "   â””â”€ ì•„ë‹ˆì˜¤: í—ˆìœ„ ë˜ëŠ” ì•…ì˜ì  ê³ ì†Œ â†’ ë¶ˆë²•í–‰ìœ„ ì„±ë¦½ ê°€ëŠ¥ì„± â†’ ì†í•´ë°°ìƒ ì²­êµ¬ ê°€ëŠ¥",
  "2. ê³ ì†Œì™€ ì†í•´ ì‚¬ì´ ì¸ê³¼ê´€ê³„ê°€ ëª…í™•í•œê°€?",
  "   â”œâ”€ ì˜ˆ: ì‹¤ì œ ì†í•´(ì¼ì‹¤ìˆ˜ìµ ë“±)ë¥¼ ì…ì¦í•  ìˆ˜ ìˆë‹¤ë©´ ë°°ìƒ ì¸ì • ê°€ëŠ¥",
  "   â””â”€ ì•„ë‹ˆì˜¤: ê³ ì†Œì™€ ì†í•´ê°€ ë¬´ê´€í•˜ê±°ë‚˜ ì¶”ì • ìˆ˜ì¤€ â†’ ì†í•´ë°°ìƒ ì¸ì • ì–´ë ¤ì›€"
]

--- end ---

ì‘ë‹µ í˜•ì‹ (JSON):{{
  "tone": "...",
  "structure": "...",
  "decision_tree": ["..."],
  "final_strategy_summary": "...",
  "recommended_links": [{{"label": "...", "url": "..."}}]
}}
"""

    llm = get_llm(model, temperature=0.2)
    messages = [
        {"role": "system", "content": "ë‹¹ì‹ ì€ ì „ëµ ë³´ì™„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
        {"role": "user", "content": prompt},
    ]

    try:
        response = llm.invoke(messages)
        return json.loads(response.content)
    except Exception as e:
        return get_default_strategy_template()


# âœ… ì „ëµ ì‹¤í–‰ íë¦„
async def run_response_strategy_with_limit(
    explanation,
    user_query,
    hyperlinks,
    model="gpt-3.5-turbo",
    previous_strategy: dict = None,  # âœ… ì¶”ê°€
):
    strategy = await generate_response_strategy(
        explanation=explanation,
        user_query=user_query,
        hyperlinks=hyperlinks,
        previous_strategy=previous_strategy,  # âœ… ì „ë‹¬
        model=model,
    )

    if strategy.get("evaluation", {}).get("needs_revision") is True:
        revised = await revise_strategy_with_feedback(
            original_strategy=strategy,
            tavily_snippets=strategy["evaluation"].get("tavily_snippets", []),
        )
        revised["evaluation"] = {"revised": True}
        return revised

    return strategy
