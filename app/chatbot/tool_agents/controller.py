import asyncio
from typing import List, Optional
from app.chatbot.tool_agents.qualifier import run_consultation_qualifier
from app.chatbot.tool_agents.planner import (
    generate_response_template,
    run_response_strategy_with_limit,
)
from app.chatbot.tool_agents.precedent import LegalPrecedentRetrievalAgent
from app.chatbot.tool_agents.executor.normalanswer import run_final_answer_generation
from app.chatbot.tool_agents.tools import async_search_consultation

# ConversationBufferMemoryë¥¼ í™œìš©í•œ ìºì‹œ í•¨ìˆ˜ë“¤ import
from app.chatbot.memory.global_cache import (
    retrieve_template_from_memory,
    store_template_in_memory,
)


async def run_full_consultation(
    user_query: str,
    search_keywords: List[str],
    model: str = "gpt-4",
    build_only: bool = False,
    stop_event: Optional[asyncio.Event] = None,  # âœ… ì¶”ê°€
) -> dict:


    # ìºì‹œ ì¡°íšŒ: ConversationBufferMemoryì—ì„œ ì €ì¥ëœ TEMPLATE_DATA ë©”ì‹œì§€ ì‚¬ìš©
    cached_data = retrieve_template_from_memory()
    if cached_data:

        template = cached_data.get("template")
        strategy = cached_data.get("strategy")
        precedent = cached_data.get("precedent")
        # ë¹Œë“œ ì „ìš© ëª¨ë“œë©´ ìºì‹œëœ ë°ì´í„° ê·¸ëŒ€ë¡œ ë°˜í™˜
        if build_only:
            return {
                "user_query": user_query,
                "template": template,
                "strategy": strategy,
                "precedent": precedent,
                "status": "build_only (cached)",
            }
        # ìµœì¢… ì‘ë‹µ ìƒì„± (ìºì‹œëœ í…œí”Œë¦¿ í™œìš©)
        final_answer = run_final_answer_generation(
            template=template,
            strategy=strategy,
            precedent=precedent,
            user_query=user_query,
            model=model,
        )

        return {
            "user_query": user_query,
            "template": template,
            "strategy": strategy,
            "precedent": precedent,
            "final_answer": final_answer,
            "status": "ok (cached)",
        }

    # ìºì‹œëœ ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±
    # 1ï¸âƒ£ Qualifier ì‹¤í–‰
    consultation_results, _, _ = await async_search_consultation(search_keywords)
    if stop_event and stop_event.is_set():

        return {"template": None, "strategy": None, "precedent": None}

    best_case = await run_consultation_qualifier(user_query, consultation_results)
    if not consultation_results:

        return {"template": None, "strategy": None, "precedent": None}
    if not all(k in best_case for k in ["title", "question", "answer"]):

        title = best_case.get("title", "ë²•ë¥ ìƒë‹´")
        question = best_case.get("question", user_query)
        answer = best_case.get(
            "answer", "ì¼ë°˜ì ì¸ ë²•ë¥  ì •ë³´ì— ê¸°ë°˜í•˜ì—¬ ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤."
        )
    else:
        title = best_case["title"]
        question = best_case["question"]
        answer = best_case["answer"]

    if stop_event and stop_event.is_set():

        return {"template": None, "strategy": None, "precedent": None}

    # 2ï¸âƒ£ Planner - í…œí”Œë¦¿ ìƒì„±
    template = await generate_response_template(title, question, answer, user_query)

    # 3ï¸âƒ£ ì „ëµ ìƒì„±
    strategy = await run_response_strategy_with_limit(
        template.get("explanation", ""),  # ğŸ” explanation ì—†ì„ ê²½ìš° ë¹ˆ ë¬¸ìì—´ë¡œ ì²˜ë¦¬
        user_query,
        template.get("hyperlinks", []),
    )

    if stop_event and stop_event.is_set():

        return {"template": None, "strategy": None, "precedent": None}

    # 4ï¸âƒ£ íŒë¡€ ê²€ìƒ‰ ë“± ë¹Œë“œ ì™„ë£Œ í›„
    precedent_agent = LegalPrecedentRetrievalAgent()
    precedent = await precedent_agent.run(
        categories=[title],
        titles=[title],
        user_input_keywords=search_keywords,
    )

    # ì¤‘ê°„ ë¹Œë“œ ë°ì´í„° êµ¬ì„± (ì—¬ê¸°ì— built í”Œë˜ê·¸ ì¶”ê°€)
    intermediate_data = {
        "template": template,
        "strategy": strategy,
        "precedent": precedent,
        "built": True,  # ê¸°ì¡´
        "built_by_llm2": True,  # âœ… í•„ìˆ˜: LLM2 ìƒì„± í…œí”Œë¦¿ì„ì„ ëª…ì‹œ
    }
    store_template_in_memory(intermediate_data)


    # ë¹Œë“œ ì „ìš© ëª¨ë“œ (GPT ë¯¸í˜¸ì¶œ)
    if build_only:
        return {
            "user_query": user_query,
            "template": template,
            "strategy": strategy,
            "precedent": precedent,
            "status": "build_only",
        }

    # 5ï¸âƒ£ ê³ ê¸‰ GPT ì‘ë‹µ ìƒì„±
    final_answer = run_final_answer_generation(
        template=template,
        strategy=strategy,
        precedent=precedent,
        user_query=user_query,
        model=model,
    )

    return {
        "user_query": user_query,
        "template": template,
        "strategy": strategy,
        "precedent": precedent,
        "final_answer": final_answer,
        "status": "ok",
    }
